# FederatedLearningProject

This project explores federated model editing techniques.

## Project Structure

The repository is organized as follows:

```text
federated-model-editing/
â”‚
â”œâ”€â”€ ğŸ“ data/                     
â”‚   â””â”€â”€ cifar100_loader.py          # CIFAR-100 dataset loading and preprocessing
â”‚
â”œâ”€â”€ ğŸ“ training/                  
â”‚   â”œâ”€â”€ FL_training.py                # Federated learning pipeline (FedAvg)
â”‚   â”œâ”€â”€ centralized_training.py       # Centralized training baseline
â”‚   â””â”€â”€ FedMETA.py                    # Federated model editing with meta-learning
â”‚
â”œâ”€â”€ ğŸ“ experiments/                 
â”‚   â”œâ”€â”€ baseline_centralized.ipynb    # Centralized training experiment
â”‚   â”œâ”€â”€ baseline_federated.ipynb      # Federated (FedAvg) experiment
â”‚   â”œâ”€â”€ model_editing.ipynb           # Sparse fine-tuning and model merging (centralized)
â”‚   â”œâ”€â”€ federated_model_editing.ipynb # Federated model editing experiments
â”‚   â””â”€â”€ FedMETA.ipynb                 # FedMETA evaluation and results      
â”‚   â””â”€â”€ models.py                     
â”œâ”€â”€ ğŸ“ checkpoints/                 
â”‚   â”œâ”€â”€ checkpointing.py              # Model checkpoint saving/loading
â”‚
â””â”€â”€ ğŸ“„ README.md                      # Project overview and structure
```

## How to run experiments

The **Experiments** folder contains notebooks that implement the code used in our experiments. These notebooks make use of functions defined in the **training**, **data**, and **checkpoints** directories.

To run each experiment, execute the corresponding notebook, ensuring that the appropriate hyperparameters for each algorithm are correctly specified.


