# -*- coding: utf-8 -*-
"""dataset_utils_local.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xg5Km7qlBxDILFaegu9GCdbHRhoFkUri
"""

import torch
import torchvision
from torchvision import transforms
from torch.utils.data import random_split
from torchvision.datasets import CIFAR100

# Come viene chiamata:
# train_set, val_set, test_set = dataset_utils.get_datasets(valid_split_perc)

def get_datasets(valid_split_perc):

  # 1. Define the transformations to apply
  # Normalization Data (mean and std over CIFAR100 dataset)
  mean = [0.5071, 0.4867, 0.4408]  # CIFAR-100 mean
  std = [0.2675, 0.2565, 0.2761]   # CIFAR-100 std

  # Trasformations for training, test, validation
  train_transform = transforms.Compose([
      transforms.Resize((32, 32)),             # Resize
      transforms.RandomHorizontalFlip(),       # RandomFlip
      transforms.RandomCrop(32, padding=4),    # RandomCrop
      transforms.ToTensor(),                   # ToTensor
      transforms.Normalize(mean, std)          # Normalizzazione
  ])

  test_val_transform = transforms.Compose([
      transforms.Resize((32, 32)),             # Resize
      transforms.ToTensor(),                   # ToTensor
      transforms.Normalize(mean, std)          # Normalizzazione
  ])


  # 2. Download the dataset

  train_val_set = CIFAR100(root='./data', train=True, download=True, transform=None)      # no transforms applied yet

  train_size = int((1 - valid_split_perc) * len(train_val_set))                           # Ex: if valid_split_perc = 0.2 → train_size = 0.8 * tot
  val_size = len(train_val_set) - train_size

  trainset, valset = random_split(train_val_set, [train_size, val_size])           # split train - valid set

  trainset.dataset.transform = train_transform                                     # apply proper transforms to training set now
  valset.dataset.transform = test_val_transform                                    # apply proper transforms to validation set now

  testset = CIFAR100(root='./data', train=False, download=True, transform=test_val_transform)  # download test set with proper transforms

  # 3. Print
  print(f"Number of images in the Training Set: {len(trainset)}")
  print(f"Number of images in the Validation Set: {len(valset)}")
  print(f"Number of images in the Test Set: {len(testset)}")
  print()
  print("✅ Datasets loaded successfully: training, validation, and test sets are ready.")

  return trainset, valset, testset

