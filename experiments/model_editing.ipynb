{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "import shutil\n",
    "import os                              # Import the 'os' module for changing directories\n",
    "os.chdir('/content/drive/MyDrive/FL')  # Change the directory\n",
    "import datetime as datetime\n",
    "import copy\n",
    "import json\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torch.utils.data import Subset, DataLoader, random_split\n",
    "\n",
    "from FederatedLearningProject.data.cifar100_loader import get_cifar100\n",
    "from FederatedLearningProject.checkpoints.checkpointing import save_checkpoint, load_checkpoint\n",
    "from FederatedLearningProject.training.centralized_training import train_and_validate, train_epoch, validate_epoch, log_to_wandb, generate_configs\n",
    "from FederatedLearningProject.training.model_editing import compute_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import FederatedLearningProject.experiments.models as models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bfd7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CIFAR100 dataset: train_set, val_set, test_set\n",
    "# The transforms are applied before returning the dataset (in the module)\n",
    "valid_split_perc = 0.2    # of the 50000 training data\n",
    "train_set, val_set, test_set = get_cifar100(valid_split_perc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e38ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for training, validation, and test sets\n",
    "# batch_size è in hyperparameter (64, 128, ..), anche num_workers (consigliato per colab 2 o 4)\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934cda6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_model = models.LinearFlexibleDino()     # original model\n",
    "o_model.freeze(12)\n",
    "o_model.to_cuda()\n",
    "o_model.debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342cf1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prendo il path dello state_dict del miglio modello che ho salvato su Drive per non dover ri-trainare sempre\n",
    "checkpoint_dir = \"/content/drive/MyDrive/FL\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "best_model_path = os.path.join(checkpoint_dir, \"best_model_locale.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796832ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copio il modello di base\n",
    "model = copy.deepcopy(o_model)\n",
    "\n",
    "# aggiorno i pesi del modello con quelli trainati\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "model.debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4719d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze(0)\n",
    "model.debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d5880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numero totale di parametri del modello:\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Numero totale di parametri: {total_params}\")\n",
    "\n",
    "# numero totale di parametri del modello attualmente allenabili:\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Parametri attualmente allenabili (trainable): {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzarli\n",
    "for name, param in model.named_parameters():\n",
    "    if 'embed' in name or 'cls_token' in name or 'backbone.norm' in name or 'head' in name:\n",
    "        print(f\"{name} - shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb4f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezzarli\n",
    "print(\"param.requires_grad = False: \")\n",
    "for name, param in model.named_parameters():\n",
    "    if 'embed' in name or 'cls_token' in name or 'backbone.norm' in name or 'head' in name:\n",
    "        param.requires_grad = False\n",
    "        print(f\"FROZEN: {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd76f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numero totale di parametri del modello:\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Numero totale di parametri: {total_params}\")\n",
    "\n",
    "# numero totale di parametri del modello attualmente allenabili:\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Parametri attualmente allenabili (trainable): {trainable_params}\")\n",
    "\n",
    "print(f\"\\n\")\n",
    "model.debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fb8dd9",
   "metadata": {},
   "source": [
    "Adesso il modello è pronto per creare la maschera con la matrice di Fisher\n",
    "Ricorda: la maschera va creata in modalità evaluation (no processi stocastici)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eade059",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858dd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check device\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec85c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mask\n",
    "mascherina=compute_mask(model, train_loader, sparsity_target=0.9, R=5, num_examples=200, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce6304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
