{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "aWeVa87_ex53",
      "metadata": {
        "id": "aWeVa87_ex53"
      },
      "outputs": [],
      "source": [
        "#!pip install wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "228da2b7",
      "metadata": {
        "id": "228da2b7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torch.utils.data import Subset, DataLoader, random_split\n",
        "import numpy as np\n",
        "import wandb\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "usCBOVfNjyQI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "usCBOVfNjyQI",
        "outputId": "879dc5cb-d84b-4994-b426-cc714da00331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcerbellifederico\u001b[0m (\u001b[33mcerbellifederico-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "wandb.login() # serve per loggare chiederà la vostrca key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "HJXJQJUAJXmo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJXJQJUAJXmo",
        "outputId": "84d0af8a-648e-4174-e946-a8074bb124d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "#repo_path = \"/content/FederatedLearningProject\"\n",
        "repo_path = \"/content/drive/MyDrive/FL_Project_FedeExperiments\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vuWKfDU7JQ_6",
      "metadata": {
        "id": "vuWKfDU7JQ_6"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(repo_path):\n",
        "    !git clone -b fede-experiments https://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@github.com/depetrofabio/FederatedLearningProject.git\n",
        "else:\n",
        "    %cd {repo_path}\n",
        "    !git pull origin fede-experiments\n",
        "\n",
        "shutil.copytree(repo_path, dest_path, dirs_exist_ok=True)\n",
        "\n",
        "# Push only with user ok\n",
        "push_to_github = input(\"Vuoi pushare le modifiche locali su GitHub? (s/n): \").strip().lower()\n",
        "if push_to_github == 's':\n",
        "    !git add .\n",
        "    !git commit -m \"Modifiche da Colab - $(date +'%d/%m/%Y %H:%M')\"\n",
        "    !git push origin fede-experiments\n",
        "    print(\" Push completato!\")\n",
        "else:\n",
        "    print(\" Push annullato.\")# Clone or update repo ->  è una mia prova per aggiornare dierattamente il mio branch lasciatela commentata o toglietela\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8582f172",
      "metadata": {
        "id": "8582f172"
      },
      "source": [
        "[testo del link](https://)CIFAR 100 contains 100 classes. There are 500 images per class in the train set and 100 per class in the test set.\n",
        "For a total of 600 images per class. So it has 50000 training examples and 10000 test examples.\n",
        "The 100 classes (fine label) are actually grouped in 20 super-classes (coarse label) => every image has 2 labels: class,superclass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d96879f8",
      "metadata": {
        "id": "d96879f8"
      },
      "outputs": [],
      "source": [
        "def get_cifar100(train=True): # https://dev.to/hyperkai/cifar100-in-pytorch-4p8d\n",
        "    ''' This function returns the train dataset CIFAR100 (50000 images).'''\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),  # image to tensor\n",
        "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2762])  # normalize the image\n",
        "    ])\n",
        "\n",
        "    return CIFAR100(root='./data', train=train, download=True, transform=transform) # NOTE: if download=True the entire (train + test) dataset is downloaded locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d3ff833",
      "metadata": {
        "id": "2d3ff833"
      },
      "outputs": [],
      "source": [
        "def split_train_val(dataset, val_ratio=0.2):\n",
        "    '''This function: TRAIN -> train + val'''\n",
        "    return random_split(dataset, [1-val_ratio, val_ratio]) # returns [train,val]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import Subset\n",
        "# from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# def stratified_split_train_val(dataset, val_ratio=0.2):\n",
        "#     '''This function: TRAIN -> train + val with stratified split to maintain class proportions'''\n",
        "\n",
        "#     # Get the labels from the dataset (assuming the labels are in dataset.targets)\n",
        "#     targets = dataset.targets if isinstance(dataset, torch.utils.data.Dataset) else np.array([y for _, y in dataset])\n",
        "\n",
        "#     sss = StratifiedShuffleSplit(n_splits=1, test_size=val_ratio, random_state=42)\n",
        "\n",
        "#     # Create train/validation splits\n",
        "#     for train_index, val_index in sss.split(np.zeros(len(targets)), targets):\n",
        "#         train_subset = Subset(dataset, train_index)\n",
        "#         val_subset = Subset(dataset, val_index)\n",
        "\n",
        "#     return train_subset, val_subset\n"
      ],
      "metadata": {
        "id": "_9OvdpE45mRY"
      },
      "id": "_9OvdpE45mRY",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e6d16af",
      "metadata": {
        "id": "9e6d16af"
      },
      "outputs": [],
      "source": [
        "def create_non_iid_splits(dataset, num_clients=100, classes_per_client= 10): # as dataset use the train (after the split train,val)\n",
        "    ''' Assign data to clients with Dirichlet distribution (simulate label skew). ATT! it only assigns different set of labels to different clients'''\n",
        "    num_classes = 100\n",
        "    # classes_per_client = num_classes/num_clients <-- TODO\n",
        "\n",
        "    if isinstance(dataset, Subset):\n",
        "        # Extract targets from the original dataset using Subset indices\n",
        "        labels = np.array(dataset.dataset.targets)[dataset.indices]\n",
        "    else:\n",
        "        # If the data are not a dataset we can access more direclty. While Subsets do not have the target attribute.\n",
        "        labels = np.array(dataset.targets)\n",
        "\n",
        "    client_data = {i: [] for i in range(num_clients)}   # create a dictionary where keys goes from 0 to num_clients-1, values are empty lists.\n",
        "    for cls in range(num_classes):\n",
        "        indices = np.where(labels == cls)[0]\n",
        "        np.random.shuffle(indices)\n",
        "        splits = np.array_split(indices, num_clients // classes_per_client) # Divides the indices into equal parts, where each part corresponds to a subset of data for clients. ( // is integer division (flor division))\n",
        "        for idx, split in enumerate(splits): # Assign each split to a client\n",
        "            client_id = (cls % classes_per_client) + (idx * classes_per_client)\n",
        "            client_data[client_id].extend(split.tolist())\n",
        "    return [Subset(dataset, indices) for indices in client_data.values()] #  the function returns a list of Subset objects, each representing the data assigned to a client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f1uwQJOSKHgl",
      "metadata": {
        "id": "f1uwQJOSKHgl"
      },
      "outputs": [],
      "source": [
        "dataset = get_cifar100()\n",
        "train_set, val_set = split_train_val(dataset)\n",
        "#train_set, val_set = stratified_split_train_val(dataset)\n",
        "\n",
        "# Create DataLoader\n",
        "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=128, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "VPVs7aY0x5l0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPVs7aY0x5l0",
        "outputId": "a7881353-6888-41e1-8b86-9997ad4ac323"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "313"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RvPTB3BVOM4r",
      "metadata": {
        "id": "RvPTB3BVOM4r"
      },
      "outputs": [],
      "source": [
        "# subset useful only to train a small fragment of dataset!!!\n",
        "subset_indices = np.random.choice(len(train_set), size=10000, replace=False)\n",
        "subset_train_dataset = Subset(train_set, subset_indices)\n",
        "train_set, val_set = split_train_val(subset_train_dataset)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=128, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "isLxBXVW9gcv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isLxBXVW9gcv",
        "outputId": "69ad7f4a-bd46-485e-b9d0-fd2a90a90228"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 3, 32, 32]) torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "# batch example\n",
        "for images, labels in train_loader:\n",
        "    print(images.shape, labels.shape)  # Dovrebbe stampare (64, 3, 32, 32) per immagini e (64,) per le etichette\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "lVyiuu-pLHAd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVyiuu-pLHAd",
        "outputId": "cacc089e-dd13-40ef-fdd9-3ca2ce986b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/dino/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dino/dino_deitsmall16_pretrain/dino_deitsmall16_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dino_deitsmall16_pretrain.pth\n",
            "100%|██████████| 82.7M/82.7M [00:00<00:00, 173MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VisionTransformer(\n",
            "  (patch_embed): PatchEmbed(\n",
            "    (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
            "  )\n",
            "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "  (blocks): ModuleList(\n",
            "    (0-11): 12 x Block(\n",
            "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (drop_path): Identity()\n",
            "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
            "  (head): Identity()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# pretrained model architecture DINO ViT-S/16\n",
        "model = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "RqiWVe89NEJC",
      "metadata": {
        "id": "RqiWVe89NEJC"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4) # il migliore che ho provato\n",
        "\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)  # momentum=0.9, weight_decay=5e-4 -> optimizer consigliato\n",
        "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "w2WnTA_ue2sX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "w2WnTA_ue2sX",
        "outputId": "c2109304-b9f1-4cf5-df73-1ab3044b7949"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250423_091041-nlg7xdxf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cerbellifederico-politecnico-di-torino/FederatedProject/runs/nlg7xdxf' target=\"_blank\">dino_vits16_run</a></strong> to <a href='https://wandb.ai/cerbellifederico-politecnico-di-torino/FederatedProject' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cerbellifederico-politecnico-di-torino/FederatedProject' target=\"_blank\">https://wandb.ai/cerbellifederico-politecnico-di-torino/FederatedProject</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cerbellifederico-politecnico-di-torino/FederatedProject/runs/nlg7xdxf' target=\"_blank\">https://wandb.ai/cerbellifederico-politecnico-di-torino/FederatedProject/runs/nlg7xdxf</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# wand.init() prepara il tracking degli iperparametri/metriche per poi registrare le performance con wandb.log()\n",
        "\n",
        "model_name = \"dino_vits16\"\n",
        "project_name = \"FederatedProject\"\n",
        "run_name = f\"{model_name}_run\"\n",
        "\n",
        "# INIZIALIZZA W&B\n",
        "wandb.init(\n",
        "    project=project_name,\n",
        "    name=run_name,\n",
        "    config={\n",
        "        \"model\": model_name,\n",
        "        \"epochs\": 20,\n",
        "        \"batch_size\": train_loader.batch_size,\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "        \"architecture\": model.__class__.__name__,\n",
        "})\n",
        "\n",
        "# Copy your config\n",
        "config = wandb.config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "mo4lpz6c3C-F",
      "metadata": {
        "id": "mo4lpz6c3C-F"
      },
      "outputs": [],
      "source": [
        "#  PERCORSO CHECKPOINT\n",
        "checkpoint_dir = \"/content/drive/MyDrive/FL_Project_FedeExperiments/checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "checkpoint_path = os.path.join(checkpoint_dir, f\"{model_name}_checkpoint.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cBdBMnxzyusN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBdBMnxzyusN",
        "outputId": "8f628467-5a6b-4913-94d3-2bf2bb0ff7f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Checkpoint caricato da /content/drive/MyDrive/FL_Project_FedeExperiments/checkpoints/dino_vits16_checkpoint.pth, riprendo da epoca 3.\n"
          ]
        }
      ],
      "source": [
        "#  RIPRENDI CHECKPOINT\n",
        "start_epoch = 1\n",
        "if os.path.exists(checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "    start_epoch = checkpoint[\"epoch\"] + 1\n",
        "    print(f\" Checkpoint caricato da {checkpoint_path}, riprendo da epoca {start_epoch}.\")\n",
        "else:\n",
        "    print(\" Nessun checkpoint trovato, inizio da epoca 1.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "xlonXgCbzymY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "xlonXgCbzymY",
        "outputId": "a788cae5-a787-40e9-c43c-653e9e86daff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] Train Loss: 4.0317,  Train Accuracy: 13.10%, Val Loss: 2.8819, Val Accuracy: 27.90%\n",
            "[Epoch 2] Train Loss: 2.5006,  Train Accuracy: 35.64%, Val Loss: 2.3255, Val Accuracy: 38.82%\n",
            "[Epoch 3] Train Loss: 2.1068,  Train Accuracy: 43.86%, Val Loss: 2.1763, Val Accuracy: 42.70%\n",
            "[Epoch 4] Train Loss: 1.8746,  Train Accuracy: 49.38%, Val Loss: 2.0422, Val Accuracy: 46.36%\n",
            "[Epoch 5] Train Loss: 1.6973,  Train Accuracy: 52.90%, Val Loss: 1.9831, Val Accuracy: 47.79%\n",
            "[Epoch 6] Train Loss: 1.5553,  Train Accuracy: 56.45%, Val Loss: 1.9536, Val Accuracy: 48.46%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-55c0e4bb89a6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# aggiorna i pesi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "start_epoch = 1\n",
        "num_epochs = wandb.config.epochs\n",
        "checkpoint_interval = 10\n",
        "\n",
        "# TRAINING\n",
        "for epoch in range(start_epoch, num_epochs + 1):\n",
        "    model.train() # Attiva modalità training\n",
        "    train_loss = 0.0  # Reset ad ogni epoca\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    # Loop sui Batch di Training\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device) # sposta i dati su gpu quando disponibile\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()    # backpropagation\n",
        "        optimizer.step()   # aggiorna i pesi\n",
        "\n",
        "        train_loss += loss.item() * images.size(0) # serve per accumulare la loss ad ogni epoca\n",
        "        _, predicted = torch.max(outputs, 1) # Ignora i valori massimi (_), e tiene solo gli indici (predicted) -> questo perchè poi confrontiamo gli indici con le labels\n",
        "        total_train += labels.size(0) # Numero di immagini nel batch corrent\n",
        "        correct_train += (predicted == labels).sum().item() # Crea un tensore booleano poi somma le TRUE e infine converte in un numero\n",
        "\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    avg_train_loss = train_loss / total_train\n",
        "\n",
        "    #  VALIDAZIONE\n",
        "    model.eval() # Attiva modalità di validation\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad(): # no calcolo gradienti\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device) # sposta i dati su gpu quando disponibile\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Calcolo loss\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0) # images.size(0) restituisce la dimensione lungo il primo asse tipo numpy, dovrebbe variare con il batch size\n",
        "                                                     # potremmo usare anche len(labels) ma con .size(0) gestiamo il caso in cui ultimo batch contenga un numero inferiore di osservazioni\n",
        "\n",
        "            # Calcolo accuratezza\n",
        "            _, predicted = torch.max(outputs, 1) # Ignora i valori massimi (_), e tiene solo gli indici (predicted) -> questo perchè poi confrontiamo gli indici con le labels\n",
        "            total += labels.size(0)   # Numero di immagini nel batch corrent\n",
        "            correct += (predicted == labels).sum().item() # Crea un tensore booleano poi somma le TRUE e infine converte in un numero\n",
        "\n",
        "    avg_val_loss = val_loss / total  # Loss media\n",
        "    val_accuracy = 100 * correct / total\n",
        "\n",
        "    # LOG SU W&B\n",
        "    wandb.log({\n",
        "        \"train_loss\": avg_train_loss,\n",
        "        \"train_accuracy\": train_accuracy,\n",
        "        \"val_loss\": avg_val_loss,\n",
        "        \"val_accuracy\": val_accuracy,\n",
        "        \"epoch\": epoch\n",
        "    }, step=epoch)\n",
        "\n",
        "    print(f\"[Epoch {epoch}] Train Loss: {avg_train_loss:.4f},  Train Accuracy: {train_accuracy:.2f}%, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "    # SALVATAGGIO CHECKPOINT -> contien stato dell'optimizer per riprendere l'addestramento\n",
        "    if epoch % checkpoint_interval == 0:\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": model.state_dict(),  # restituisce un dizionario Python che contiene tutti i parametri apprendibili del modello (pesi e bias)\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"train_loss\": avg_train_loss,\n",
        "            \"val_loss\": avg_val_loss,\n",
        "        }, checkpoint_path)\n",
        "        print(f\" Checkpoint salvato su Drive: {checkpoint_path}\")\n",
        "\n",
        "        #  (Opzionale) LOG ARTIFACT SU W&B -> dobbiamo capire se farlo o no, se i checkpoint sono molto grandi (es. >1GB), meglio salvarli localmente\n",
        "        # potrebbe avere senso salvarci il miglior modello ma ora con solo il modello consigliato si pùò tralasciare\n",
        "\n",
        "        artifact = wandb.Artifact(f\"{model_name}_checkpoint_ep{epoch}\", type=\"model\")\n",
        "        artifact.add_file(checkpoint_path)\n",
        "        wandb.log_artifact(artifact)\n",
        "\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}