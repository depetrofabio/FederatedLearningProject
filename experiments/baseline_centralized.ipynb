{"cells":[{"cell_type":"code","execution_count":null,"id":"228da2b7","metadata":{"id":"228da2b7"},"outputs":[],"source":["import numpy as np\n","import wandb\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","import shutil\n","import os                              # Import the 'os' module for changing directories\n","os.chdir('/content/drive/MyDrive/FL')  # Change the directory\n"]},{"cell_type":"code","execution_count":null,"id":"f27d1321","metadata":{"id":"f27d1321"},"outputs":[],"source":["import torch\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","\n","import torch.nn as nn\n","import torchvision\n","from torchvision import transforms\n","from torchvision.datasets import CIFAR100\n","from torch.utils.data import Subset, DataLoader, random_split\n","\n","from FederatedLearningProject.data.cifar100_loader import get_cifar100\n","import FederatedLearningProject.checkpoints.checkpointing as checkpointing\n","from FederatedLearningProject.training.centralized_training import train_and_validate\n","import FederatedLearningProject.experiments.models as models"]},{"cell_type":"code","execution_count":null,"id":"usCBOVfNjyQI","metadata":{"id":"usCBOVfNjyQI"},"outputs":[],"source":["wandb.login() # Ask for your API key for logging in to the wandb library."]},{"cell_type":"code","execution_count":null,"id":"f1uwQJOSKHgl","metadata":{"id":"f1uwQJOSKHgl"},"outputs":[],"source":["# Import CIFAR100 dataset: train_set, val_set, test_set\n","# The transforms are applied before returning the dataset (in the module)\n","valid_split_perc = 0.2    # of the 50000 training data\n","train_set, val_set, test_set = get_cifar100(valid_split_perc)"]},{"cell_type":"code","execution_count":null,"id":"c_UDv-rPjVSj","metadata":{"id":"c_UDv-rPjVSj"},"outputs":[],"source":["# Create DataLoaders for training, validation, and test sets\n","# batch_size è in hyperparameter (64, 128, ..), anche num_workers (consigliato per colab 2 o 4)\n","train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=2)\n","test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)"]},{"cell_type":"markdown","id":"TaKru93QF_8C","metadata":{"id":"TaKru93QF_8C"},"source":["\n","### Possible Models\n","|                        | **Simple linear head**                               | **MLP head w/ Dropout**                                                      |\n","| :--------------------- | :--------------------------------------------------- | :--------------------------------------------------------------------------- |\n","| **Definition**         | `nn.Linear(384 → 100)`                               | `Dropout → Linear(384 → 256) → ReLU → Dropout → Linear(256 → 100)`           |\n","| **# trainable params** | 384×100 + 100 ≈ **38 500**                           | 384×256+256 + 256×100+100 ≈ **123 000**                                      |\n","| **Regularization**     | none                                                 | dropout on both layers                                                       |\n","| **Expressive power**   | low  – just a single hyperplane on the CLS embedding | higher – small nonlinear bottleneck can learn more complex features in heads |\n","| **Compute / memory**   | minimal                                              | \\~3× more weights, a bit more forward/backward cost                          |\n","\n","---\n","\n","**Appunto sui layer di testa:**\n","\n","1. **`self.classifier`**\n","\n","   * **Cosa contiene?** Un singolo `nn.Linear(embed_dim → num_classes)`.\n","   * **Quando usarlo?** Se vuoi un *linear probe* puro: un solo layer che prende il CLS token e mappa direttamente alle classi.\n","   * **Pro:** estremamente leggero (∼38 K parametri), veloce da addestrare e da inferire.\n","   * **Contro:** capacità espressiva minima (è solo un’iper‐superficie lineare sullo spazio degli embedding).\n","\n","2. **`self.head`**\n","\n","   * **Cosa contiene?** Una piccola sequenza (`nn.Sequential`) di layer:\n","\n","     * Dropout\n","     * Linear (embed\\_dim → hidden\\_dim)\n","     * ReLU\n","     * Dropout\n","     * Linear (hidden\\_dim → num\\_classes)\n","   * **Quando usarlo?** Se vuoi dare al tuo “probe” un po’ più di potenza di calcolo, trasformando non-linearmente il CLS prima della classificazione.\n","   * **Pro:** maggiore capacità di apprendere rappresentazioni complesse nella testa, un minimo di regolarizzazione via dropout.\n","   * **Contro:** più pesante (∼3× parametri in più rispetto al solo `classifier`), leggermente più lento da addestrare e inferire.\n","\n","---\n","\n","### Perché una piuttosto che l’altra?\n","\n","* **Vincoli di risorse** (GPU/RAM, tempo d’addestramento):\n","\n","  * Se sei sotto forte pressione computazionale o vuoi risultati rapidi, opti per `self.classifier`.\n","* **Prestazioni** (accuratezza su dataset piccolo/mediamente grande come CIFAR-100):\n","\n","  * Se noti che il linear probe raggiunge un plateau basso, un piccolo MLP (`self.head`) può guadagnare qualche punto percentuale in più.\n","* **Semplicità vs flessibilità**:\n","\n","  * Con una sola `classifier` hai un codice più pulito e diretto.\n","  * Con `head` puoi sperimentare — cambiare `hidden_dim`, aggiungere altro dropout, batchnorm o ulteriori layer.\n","\n","In definitiva, **il nome** (`classifier` vs `head`) è arbitrario: serve a rendere più chiaro nel codice di che “peso” stiamo parlando. Se hai un solo layer, chiamalo `classifier`; se invece è un blocco più articolato, chiamalo `head` o `projection_head`, per tener separata la parte “feature extractor” (backbone) dalla parte “feature consumer” (testa di classificazione).\n"]},{"cell_type":"code","execution_count":null,"id":"WKtFc5PxZXB3","metadata":{"id":"WKtFc5PxZXB3"},"outputs":[],"source":["# --- RETRIEVE THE MODEL --- #\n","# with:\n","\n","## all backbone frozen\n","# model = models.DinoOnlyHead()\n","\n","## 3 unfrozen blocks\n","model = models.HeadAnd3Blocks()"]},{"cell_type":"code","execution_count":null,"id":"1edf229e","metadata":{"id":"1edf229e"},"outputs":[],"source":["# Move model to GPU\n","model.to_cuda()"]},{"cell_type":"code","execution_count":null,"id":"6eb8840f","metadata":{"id":"6eb8840f"},"outputs":[],"source":["### Debug model (optional)\n","model.debug()"]},{"cell_type":"code","execution_count":null,"id":"RqiWVe89NEJC","metadata":{"id":"RqiWVe89NEJC"},"outputs":[],"source":["# --- OPTIMIZER AND LOSS FUNCTION --- #\n","learning_rate = 1e-4\n","momentum = 0.9\n","weight_decay = 5e-5\n","epochs = 50\n","\n","# Optimizer instantiation:\n","optimizer = torch.optim.SGD(\n","    filter(lambda p: p.requires_grad, model.parameters()),\n","    lr=learning_rate, # Example LR\n","    weight_decay=weight_decay,\n","    momentum=momentum\n",")\n","# scheduler\n","scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n","# loss f()\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"id":"w2WnTA_ue2sX","metadata":{"id":"w2WnTA_ue2sX"},"outputs":[],"source":["### Set up W&B\n","\n","model_name = \"dino_vits16\"\n","project_name = \"FederatedProject\"\n","run_name = f\"{model_name}_run\"\n","\n","# INITIALIZE W&B\n","wandb.init(\n","    project=project_name,\n","    name=run_name,\n","    config={\n","        \"model\": \"dino_vits16\",\n","        \"epochs\": epochs,\n","        \"batch_size\": train_loader.batch_size,\n","        \"learning_rate\": learning_rate,  # Use fixed value\n","        \"weight_decay\": weight_decay,\n","        \"momentum\": momentum,\n","        \"architecture\": model.__class__.__name__,\n","    }\n",")\n","\n","# Copy your config\n","config = wandb.config\n"]},{"cell_type":"code","execution_count":null,"id":"mo4lpz6c3C-F","metadata":{"id":"mo4lpz6c3C-F"},"outputs":[],"source":["#  SET CHECKPOINT DIRECTORY\n","checkpoint_dir = \"/content/drive/MyDrive/FL/FederatedLearningProject/checkpoints\""]},{"cell_type":"code","execution_count":null,"id":"cBdBMnxzyusN","metadata":{"id":"cBdBMnxzyusN"},"outputs":[],"source":["# RECOVER CHECKPOINT\n","# # the function already do model.load_state_dict(checkpoint_data[\"model_state_dict\"])\n","#                           scheduler.load_state_dict(checkpoint_data[\"scheduler_state_dict\"])\n","#                           optimizer.load_state_dict(checkpoint_data[\"optimizer_state_dict\"])\n","# anyway it returns all the data (model data) if needed\n","\n","start_epoch, model_data = checkpointing.load_checkpoint(model=model, optimizer=optimizer, scheduler=scheduler)\n"]},{"cell_type":"code","execution_count":null,"id":"1dd82f58","metadata":{"id":"1dd82f58"},"outputs":[],"source":["## Display some informations ##\n","print(\"Model:\", model_name)\n","print(\"Train set size:\", len(train_set))\n","print(\"Validation set size:\", len(val_set))\n","print(\"Batch size:\", train_loader.batch_size)\n","print(\"Number of epochs:\", config.epochs)\n","print(\"DataLoader: \")\n","print(\"Learning rate:\", optimizer.param_groups[0]['lr'])\n","print(\"Architecture:\", model.__class__.__name__)\n","print(\"Optimizer:\", optimizer)\n","print(\"Loss function:\", criterion)\n","print(\"Checkpoint directory:\", checkpoint_dir)\n","print()\n","\n","print(\"Train Loader Information:\")\n","print(f\"  Number of batches: {len(train_loader)}\")\n","print(f\"  Batch size: {train_loader.batch_size}\")\n","# Get the dimension of a single batch\n","for images, labels in train_loader:\n","  print(f\"  Dimension of 1 batch (images): {images.shape}\")\n","  print(f\"  Dimension of 1 batch (labels): {labels.shape}\")\n","  break  # Exit the loop after processing one batch\n","print()\n","\n","print(\"\\nValidation Loader Information:\")\n","print(f\"  Number of batches: {len(val_loader)}\")\n","print(f\"  Batch size: {val_loader.batch_size}\")\n","# Get the dimension of a single batch\n","for images, labels in val_loader:\n","  print(f\"  Dimension of 1 batch (images): {images.shape}\")\n","  print(f\"  Dimension of 1 batch (labels): {labels.shape}\")\n","  break  # Exit the loop after processing one batch\n","print()\n","\n","# Check for CUDA availability\n","print(\"CUDA AVAIABILITY:\")\n","if torch.cuda.is_available():\n","    print(\"CUDA is available. Using GPU.\")\n","    print(\"Number of GPUs:\", torch.cuda.device_count())\n","    print(\"Current GPU:\", torch.cuda.current_device())\n","    print(\"GPU Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n","else:\n","    print(\"CUDA is not available. Using CPU.\")\n","\n","# Print model architecture summary\n","print(\"\\nMODEL ARCHITECTURE:\")\n","print(model)\n"]},{"cell_type":"code","execution_count":null,"id":"3ZGaA_bF5Cpy","metadata":{"id":"3ZGaA_bF5Cpy"},"outputs":[],"source":["# --- TRAINING LOOP ---\n","# Call to the training loop function\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model_name = \"dino_vits16\"\n","checkpoint_path = f\"{checkpoint_dir}/{model_name}_checkpoint.pth\"\n","train_and_validate(start_epoch, model=model, train_loader=train_loader, val_loader=val_loader, scheduler=scheduler, optimizer=optimizer, criterion=criterion, device=device, checkpoint_path=checkpoint_path, num_epochs=50, checkpoint_interval=10)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.9"}},"nbformat":4,"nbformat_minor":5}