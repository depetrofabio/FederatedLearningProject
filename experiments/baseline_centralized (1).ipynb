{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "228da2b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26119,
     "status": "ok",
     "timestamp": 1746827981196,
     "user": {
      "displayName": "Niccolò",
      "userId": "00690440481202077065"
     },
     "user_tz": -120
    },
    "id": "228da2b7",
    "outputId": "0db81657-f27d-42db-b3d9-7946a08fb431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "import shutil\n",
    "import os                              # Import the 'os' module for changing directories\n",
    "os.chdir('/content/drive/MyDrive/FL')  # Change the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f27d1321",
   "metadata": {
    "executionInfo": {
     "elapsed": 11860,
     "status": "ok",
     "timestamp": 1746827993059,
     "user": {
      "displayName": "Niccolò",
      "userId": "00690440481202077065"
     },
     "user_tz": -120
    },
    "id": "f27d1321"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torch.utils.data import Subset, DataLoader, random_split\n",
    "\n",
    "from FederatedLearningProject.data.cifar100_loader import get_cifar100\n",
    "import FederatedLearningProject.checkpoints.checkpointing as checkpointing\n",
    "from FederatedLearningProject.training.centralized_training import train_and_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "usCBOVfNjyQI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "executionInfo": {
     "elapsed": 17618,
     "status": "ok",
     "timestamp": 1746828010675,
     "user": {
      "displayName": "Niccolò",
      "userId": "00690440481202077065"
     },
     "user_tz": -120
    },
    "id": "usCBOVfNjyQI",
    "outputId": "358765d9-e616-435e-bbb5-a13b328e7ac6"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnicco-to\u001b[0m (\u001b[33mnicco-to-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login() # Ask for your API key for logging in to the wandb library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1uwQJOSKHgl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11904,
     "status": "ok",
     "timestamp": 1746828022580,
     "user": {
      "displayName": "Niccolò",
      "userId": "00690440481202077065"
     },
     "user_tz": -120
    },
    "id": "f1uwQJOSKHgl",
    "outputId": "b91b108a-d8f5-4ab8-c877-b5923d2b757d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in Training Set:   40000\n",
      "Number of images in Validation Set: 10000\n",
      "Number of images in Test Set:       10000\n",
      "✅ Datasets loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Import CIFAR100 dataset: train_set, val_set, test_set\n",
    "# The transforms are applied before returning the dataset (in the module)\n",
    "\n",
    "valid_split_perc = 0.2    # of the 50000 training data\n",
    "train_set, val_set, test_set = get_cifar100(valid_split_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c_UDv-rPjVSj",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1746828022595,
     "user": {
      "displayName": "Niccolò",
      "userId": "00690440481202077065"
     },
     "user_tz": -120
    },
    "id": "c_UDv-rPjVSj"
   },
   "outputs": [],
   "source": [
    "# Create DataLoaders for training, validation, and test sets\n",
    "\n",
    "# batch_size è in hyperparameter (64, 128, ..), anche num_workers (consigliato per colab 2 o 4)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TaKru93QF_8C",
   "metadata": {
    "id": "TaKru93QF_8C"
   },
   "source": [
    "\n",
    "### Possible Models\n",
    "|                        | **Simple linear head**                               | **MLP head w/ Dropout**                                                      |\n",
    "| :--------------------- | :--------------------------------------------------- | :--------------------------------------------------------------------------- |\n",
    "| **Definition**         | `nn.Linear(384 → 100)`                               | `Dropout → Linear(384 → 256) → ReLU → Dropout → Linear(256 → 100)`           |\n",
    "| **# trainable params** | 384×100 + 100 ≈ **38 500**                           | 384×256+256 + 256×100+100 ≈ **123 000**                                      |\n",
    "| **Regularization**     | none                                                 | dropout on both layers                                                       |\n",
    "| **Expressive power**   | low  – just a single hyperplane on the CLS embedding | higher – small nonlinear bottleneck can learn more complex features in heads |\n",
    "| **Compute / memory**   | minimal                                              | \\~3× more weights, a bit more forward/backward cost                          |\n",
    "\n",
    "---\n",
    "\n",
    "**Appunto sui layer di testa:**\n",
    "\n",
    "1. **`self.classifier`**\n",
    "\n",
    "   * **Cosa contiene?** Un singolo `nn.Linear(embed_dim → num_classes)`.\n",
    "   * **Quando usarlo?** Se vuoi un *linear probe* puro: un solo layer che prende il CLS token e mappa direttamente alle classi.\n",
    "   * **Pro:** estremamente leggero (∼38 K parametri), veloce da addestrare e da inferire.\n",
    "   * **Contro:** capacità espressiva minima (è solo un’iper‐superficie lineare sullo spazio degli embedding).\n",
    "\n",
    "2. **`self.head`**\n",
    "\n",
    "   * **Cosa contiene?** Una piccola sequenza (`nn.Sequential`) di layer:\n",
    "\n",
    "     * Dropout\n",
    "     * Linear (embed\\_dim → hidden\\_dim)\n",
    "     * ReLU\n",
    "     * Dropout\n",
    "     * Linear (hidden\\_dim → num\\_classes)\n",
    "   * **Quando usarlo?** Se vuoi dare al tuo “probe” un po’ più di potenza di calcolo, trasformando non-linearmente il CLS prima della classificazione.\n",
    "   * **Pro:** maggiore capacità di apprendere rappresentazioni complesse nella testa, un minimo di regolarizzazione via dropout.\n",
    "   * **Contro:** più pesante (∼3× parametri in più rispetto al solo `classifier`), leggermente più lento da addestrare e inferire.\n",
    "\n",
    "---\n",
    "\n",
    "### Perché una piuttosto che l’altra?\n",
    "\n",
    "* **Vincoli di risorse** (GPU/RAM, tempo d’addestramento):\n",
    "\n",
    "  * Se sei sotto forte pressione computazionale o vuoi risultati rapidi, opti per `self.classifier`.\n",
    "* **Prestazioni** (accuratezza su dataset piccolo/mediamente grande come CIFAR-100):\n",
    "\n",
    "  * Se noti che il linear probe raggiunge un plateau basso, un piccolo MLP (`self.head`) può guadagnare qualche punto percentuale in più.\n",
    "* **Semplicità vs flessibilità**:\n",
    "\n",
    "  * Con una sola `classifier` hai un codice più pulito e diretto.\n",
    "  * Con `head` puoi sperimentare — cambiare `hidden_dim`, aggiungere altro dropout, batchnorm o ulteriori layer.\n",
    "\n",
    "In definitiva, **il nome** (`classifier` vs `head`) è arbitrario: serve a rendere più chiaro nel codice di che “peso” stiamo parlando. Se hai un solo layer, chiamalo `classifier`; se invece è un blocco più articolato, chiamalo `head` o `projection_head`, per tener separata la parte “feature extractor” (backbone) dalla parte “feature consumer” (testa di classificazione).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WKtFc5PxZXB3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4016,
     "status": "ok",
     "timestamp": 1746828026612,
     "user": {
      "displayName": "Niccolò",
      "userId": "00690440481202077065"
     },
     "user_tz": -120
    },
    "id": "WKtFc5PxZXB3",
    "outputId": "6ffe1130-f787-46a1-c1f9-40d2b6023341"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/dino/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/dino/dino_deitsmall16_pretrain/dino_deitsmall16_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dino_deitsmall16_pretrain.pth\n",
      "100%|██████████| 82.7M/82.7M [00:00<00:00, 213MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=384, out_features=256, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=256, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Freeze only the first 9 blocks of the ViT backbone\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "backbone = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
    "\n",
    "# Freeze patch embedding and dropout\n",
    "for p in backbone.patch_embed.parameters():  # embedding vectors sono rappresentazioni numeriche dei dati\n",
    "    p.requires_grad = False\n",
    "\n",
    "backbone.pos_embed.requires_grad = False\n",
    "backbone.cls_token.requires_grad = False\n",
    "\n",
    "\"\"\"\n",
    "pos_drop is likely an nn.Dropout layer associated with positional embeddings. nn.Dropout layers themselves don't have learnable parameters\n",
    "that are updated during backpropagation (only a dropout rate, which is a hyperparameter). So, iterating through parameters() of a standard\n",
    "dropout layer might yield an empty iterator or no parameters that gradients flow through. The main control over dropout is its train() or\n",
    "eval() mode. However, if pos_drop were a custom module with learnable parameters, this would freeze them. This line is unlikely to cause\n",
    "issues but might not have a significant effect if pos_drop is a standard nn.Dropout.\n",
    "\n",
    "for p in backbone.pos_drop.parameters():     # da verificare, non dovrebbero esserci parametri trainabili nei drop out layers\n",
    "    p.requires_grad = False\n",
    "\"\"\"\n",
    "\n",
    "# Define the classifier head with optional dropout/MLP\n",
    "class DinoClassifier(nn.Module):\n",
    "    def __init__(self, backbone, num_classes=100, hidden_dim=256, drop=0.5): # hidden_dim = dimensione del layer della nn\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        embed_dim = backbone.embed_dim  # 384 for ViT-S/16\n",
    "        self.classifier = nn.Sequential(\n",
    "            # nn.Dropout(drop),                # solitamnete non si fa il dropout prima dell'input layer, da capire\n",
    "            nn.Linear(embed_dim, hidden_dim),     # from 384 to 256\n",
    "            nn.ReLU(inplace=True), # capire meglio inplace\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(hidden_dim, num_classes)    # from 256 to 100\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.backbone.get_intermediate_layers(x, n=1)[0] # take the output features from DiNo's backbone\n",
    "        cls = feats[:, 0]                                        #\n",
    "        return self.classifier(cls)\n",
    "\n",
    "# Instantiate model and move to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DinoClassifier(backbone, num_classes=100).to(device)\n",
    "\n",
    "# Freeze first 9 blocks\n",
    "for block in model.backbone.blocks[0:9]:\n",
    "    block.eval()\n",
    "    for param in block.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Unfreeze remaining blocks (if needed)\n",
    "for block in model.backbone.blocks[9:]:\n",
    "    block.train()\n",
    "    for param in block.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "model.classifier.train()\n",
    "\n",
    "# Set backbone to train mode (so dropout works during training)\n",
    "# model.backbone.train()  # Ensure backbone is in training mode, non dovrebbe modificare i blocchi freezzati\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "y-h5o7y1CQHP",
   "metadata": {
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1746828026686,
     "user": {
      "displayName": "Niccolò",
      "userId": "00690440481202077065"
     },
     "user_tz": -120
    },
    "id": "y-h5o7y1CQHP"
   },
   "outputs": [],
   "source": [
    "def debug_model(model: nn.Module, model_name: str = \"Model\"):\n",
    "    \"\"\"\n",
    "    Prints debugging information about a PyTorch model.\n",
    "\n",
    "    Information includes:\n",
    "    - Overall device of the first parameter (indicative of model's primary device).\n",
    "    - For each named parameter:\n",
    "        - Full parameter name.\n",
    "        - Device of the parameter.\n",
    "        - Whether the parameter requires gradients (is frozen or not).\n",
    "        - Inferred block index if the name matches a ViT-like structure.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Debugging {model_name} ---\")\n",
    "\n",
    "    # Check overall model device (based on the first parameter)\n",
    "    try:\n",
    "        first_param_device = next(model.parameters()).device\n",
    "        print(f\"{model_name} is primarily on device: {first_param_device}\")\n",
    "    except StopIteration:\n",
    "        print(f\"{model_name} has no parameters.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nParameter Details (Name | Device | Requires Grad? | Inferred Block):\")\n",
    "    for name, param in model.named_parameters():\n",
    "        device = param.device\n",
    "        requires_grad = param.requires_grad\n",
    "\n",
    "        block_info = \"N/A\"\n",
    "        # Try to infer block index for ViT-like models\n",
    "        if \"blocks.\" in name:\n",
    "            try:\n",
    "                # e.g., name = \"blocks.0.attn.qkv.weight\"\n",
    "                block_idx_str = name.split(\"blocks.\")[1].split(\".\")[0]\n",
    "                if block_idx_str.isdigit():\n",
    "                    block_info = f\"Block {block_idx_str}\"\n",
    "            except IndexError:\n",
    "                block_info = \"Block (parse error)\"\n",
    "\n",
    "        print(f\"- {name:<50} | {str(device):<10} | {str(requires_grad):<15} | {block_info}\")\n",
    "\n",
    "    # You can add more specific checks here, e.g., for model mode (train/eval)\n",
    "    print(f\"{model_name} is in {'training' if model.training else 'evaluation'} mode.\")\n",
    "    print(f\"--- End Debugging {model_name} ---\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "DpbqVvF7DRCC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1746828026693,
     "user": {
      "displayName": "Niccolò",
      "userId": "00690440481202077065"
     },
     "user_tz": -120
    },
    "id": "DpbqVvF7DRCC",
    "outputId": "8641863e-215a-452a-9e04-ab7826b73ac6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Debugging Model ---\n",
      "Model is primarily on device: cuda:0\n",
      "\n",
      "Parameter Details (Name | Device | Requires Grad? | Inferred Block):\n",
      "- backbone.cls_token                                 | cuda:0     | False           | N/A\n",
      "- backbone.pos_embed                                 | cuda:0     | False           | N/A\n",
      "- backbone.patch_embed.proj.weight                   | cuda:0     | False           | N/A\n",
      "- backbone.patch_embed.proj.bias                     | cuda:0     | False           | N/A\n",
      "- backbone.blocks.0.norm1.weight                     | cuda:0     | False           | Block 0\n",
      "- backbone.blocks.0.norm1.bias                       | cuda:0     | False           | Block 0\n",
      "- backbone.blocks.0.attn.qkv.weight                  | cuda:0     | False           | Block 0\n",
      "- backbone.blocks.0.attn.qkv.bias                    | cuda:0     | False           | Block 0\n",
      "- backbone.blocks.0.attn.proj.weight                 | cuda:0     | False           | Block 0\n",
      "- backbone.blocks.0.attn.proj.bias                   | cuda:0     | False           | Block 0\n",
      "- backbone.blocks.0.norm2.weight                     | cuda:0     | False           | Block 0\n",
      "- backbone.blocks.0.norm2.bias                       | cuda:0     | False           | Block 0\n",
      "- backbone.blocks.0.mlp.fc1.weight                   | cuda:0     | False           | Block 0\n",
      "- backbone.blocks.0.mlp.fc1.bias                     | cuda:0     | False           | Block 0\n",
      "- backbone.blocks.0.mlp.fc2.weight                   | cuda:0     | False           | Block 0\n",
      "- backbone.blocks.0.mlp.fc2.bias                     | cuda:0     | False           | Block 0\n",
      "- backbone.blocks.1.norm1.weight                     | cuda:0     | False           | Block 1\n",
      "- backbone.blocks.1.norm1.bias                       | cuda:0     | False           | Block 1\n",
      "- backbone.blocks.1.attn.qkv.weight                  | cuda:0     | False           | Block 1\n",
      "- backbone.blocks.1.attn.qkv.bias                    | cuda:0     | False           | Block 1\n",
      "- backbone.blocks.1.attn.proj.weight                 | cuda:0     | False           | Block 1\n",
      "- backbone.blocks.1.attn.proj.bias                   | cuda:0     | False           | Block 1\n",
      "- backbone.blocks.1.norm2.weight                     | cuda:0     | False           | Block 1\n",
      "- backbone.blocks.1.norm2.bias                       | cuda:0     | False           | Block 1\n",
      "- backbone.blocks.1.mlp.fc1.weight                   | cuda:0     | False           | Block 1\n",
      "- backbone.blocks.1.mlp.fc1.bias                     | cuda:0     | False           | Block 1\n",
      "- backbone.blocks.1.mlp.fc2.weight                   | cuda:0     | False           | Block 1\n",
      "- backbone.blocks.1.mlp.fc2.bias                     | cuda:0     | False           | Block 1\n",
      "- backbone.blocks.2.norm1.weight                     | cuda:0     | False           | Block 2\n",
      "- backbone.blocks.2.norm1.bias                       | cuda:0     | False           | Block 2\n",
      "- backbone.blocks.2.attn.qkv.weight                  | cuda:0     | False           | Block 2\n",
      "- backbone.blocks.2.attn.qkv.bias                    | cuda:0     | False           | Block 2\n",
      "- backbone.blocks.2.attn.proj.weight                 | cuda:0     | False           | Block 2\n",
      "- backbone.blocks.2.attn.proj.bias                   | cuda:0     | False           | Block 2\n",
      "- backbone.blocks.2.norm2.weight                     | cuda:0     | False           | Block 2\n",
      "- backbone.blocks.2.norm2.bias                       | cuda:0     | False           | Block 2\n",
      "- backbone.blocks.2.mlp.fc1.weight                   | cuda:0     | False           | Block 2\n",
      "- backbone.blocks.2.mlp.fc1.bias                     | cuda:0     | False           | Block 2\n",
      "- backbone.blocks.2.mlp.fc2.weight                   | cuda:0     | False           | Block 2\n",
      "- backbone.blocks.2.mlp.fc2.bias                     | cuda:0     | False           | Block 2\n",
      "- backbone.blocks.3.norm1.weight                     | cuda:0     | False           | Block 3\n",
      "- backbone.blocks.3.norm1.bias                       | cuda:0     | False           | Block 3\n",
      "- backbone.blocks.3.attn.qkv.weight                  | cuda:0     | False           | Block 3\n",
      "- backbone.blocks.3.attn.qkv.bias                    | cuda:0     | False           | Block 3\n",
      "- backbone.blocks.3.attn.proj.weight                 | cuda:0     | False           | Block 3\n",
      "- backbone.blocks.3.attn.proj.bias                   | cuda:0     | False           | Block 3\n",
      "- backbone.blocks.3.norm2.weight                     | cuda:0     | False           | Block 3\n",
      "- backbone.blocks.3.norm2.bias                       | cuda:0     | False           | Block 3\n",
      "- backbone.blocks.3.mlp.fc1.weight                   | cuda:0     | False           | Block 3\n",
      "- backbone.blocks.3.mlp.fc1.bias                     | cuda:0     | False           | Block 3\n",
      "- backbone.blocks.3.mlp.fc2.weight                   | cuda:0     | False           | Block 3\n",
      "- backbone.blocks.3.mlp.fc2.bias                     | cuda:0     | False           | Block 3\n",
      "- backbone.blocks.4.norm1.weight                     | cuda:0     | False           | Block 4\n",
      "- backbone.blocks.4.norm1.bias                       | cuda:0     | False           | Block 4\n",
      "- backbone.blocks.4.attn.qkv.weight                  | cuda:0     | False           | Block 4\n",
      "- backbone.blocks.4.attn.qkv.bias                    | cuda:0     | False           | Block 4\n",
      "- backbone.blocks.4.attn.proj.weight                 | cuda:0     | False           | Block 4\n",
      "- backbone.blocks.4.attn.proj.bias                   | cuda:0     | False           | Block 4\n",
      "- backbone.blocks.4.norm2.weight                     | cuda:0     | False           | Block 4\n",
      "- backbone.blocks.4.norm2.bias                       | cuda:0     | False           | Block 4\n",
      "- backbone.blocks.4.mlp.fc1.weight                   | cuda:0     | False           | Block 4\n",
      "- backbone.blocks.4.mlp.fc1.bias                     | cuda:0     | False           | Block 4\n",
      "- backbone.blocks.4.mlp.fc2.weight                   | cuda:0     | False           | Block 4\n",
      "- backbone.blocks.4.mlp.fc2.bias                     | cuda:0     | False           | Block 4\n",
      "- backbone.blocks.5.norm1.weight                     | cuda:0     | False           | Block 5\n",
      "- backbone.blocks.5.norm1.bias                       | cuda:0     | False           | Block 5\n",
      "- backbone.blocks.5.attn.qkv.weight                  | cuda:0     | False           | Block 5\n",
      "- backbone.blocks.5.attn.qkv.bias                    | cuda:0     | False           | Block 5\n",
      "- backbone.blocks.5.attn.proj.weight                 | cuda:0     | False           | Block 5\n",
      "- backbone.blocks.5.attn.proj.bias                   | cuda:0     | False           | Block 5\n",
      "- backbone.blocks.5.norm2.weight                     | cuda:0     | False           | Block 5\n",
      "- backbone.blocks.5.norm2.bias                       | cuda:0     | False           | Block 5\n",
      "- backbone.blocks.5.mlp.fc1.weight                   | cuda:0     | False           | Block 5\n",
      "- backbone.blocks.5.mlp.fc1.bias                     | cuda:0     | False           | Block 5\n",
      "- backbone.blocks.5.mlp.fc2.weight                   | cuda:0     | False           | Block 5\n",
      "- backbone.blocks.5.mlp.fc2.bias                     | cuda:0     | False           | Block 5\n",
      "- backbone.blocks.6.norm1.weight                     | cuda:0     | False           | Block 6\n",
      "- backbone.blocks.6.norm1.bias                       | cuda:0     | False           | Block 6\n",
      "- backbone.blocks.6.attn.qkv.weight                  | cuda:0     | False           | Block 6\n",
      "- backbone.blocks.6.attn.qkv.bias                    | cuda:0     | False           | Block 6\n",
      "- backbone.blocks.6.attn.proj.weight                 | cuda:0     | False           | Block 6\n",
      "- backbone.blocks.6.attn.proj.bias                   | cuda:0     | False           | Block 6\n",
      "- backbone.blocks.6.norm2.weight                     | cuda:0     | False           | Block 6\n",
      "- backbone.blocks.6.norm2.bias                       | cuda:0     | False           | Block 6\n",
      "- backbone.blocks.6.mlp.fc1.weight                   | cuda:0     | False           | Block 6\n",
      "- backbone.blocks.6.mlp.fc1.bias                     | cuda:0     | False           | Block 6\n",
      "- backbone.blocks.6.mlp.fc2.weight                   | cuda:0     | False           | Block 6\n",
      "- backbone.blocks.6.mlp.fc2.bias                     | cuda:0     | False           | Block 6\n",
      "- backbone.blocks.7.norm1.weight                     | cuda:0     | False           | Block 7\n",
      "- backbone.blocks.7.norm1.bias                       | cuda:0     | False           | Block 7\n",
      "- backbone.blocks.7.attn.qkv.weight                  | cuda:0     | False           | Block 7\n",
      "- backbone.blocks.7.attn.qkv.bias                    | cuda:0     | False           | Block 7\n",
      "- backbone.blocks.7.attn.proj.weight                 | cuda:0     | False           | Block 7\n",
      "- backbone.blocks.7.attn.proj.bias                   | cuda:0     | False           | Block 7\n",
      "- backbone.blocks.7.norm2.weight                     | cuda:0     | False           | Block 7\n",
      "- backbone.blocks.7.norm2.bias                       | cuda:0     | False           | Block 7\n",
      "- backbone.blocks.7.mlp.fc1.weight                   | cuda:0     | False           | Block 7\n",
      "- backbone.blocks.7.mlp.fc1.bias                     | cuda:0     | False           | Block 7\n",
      "- backbone.blocks.7.mlp.fc2.weight                   | cuda:0     | False           | Block 7\n",
      "- backbone.blocks.7.mlp.fc2.bias                     | cuda:0     | False           | Block 7\n",
      "- backbone.blocks.8.norm1.weight                     | cuda:0     | False           | Block 8\n",
      "- backbone.blocks.8.norm1.bias                       | cuda:0     | False           | Block 8\n",
      "- backbone.blocks.8.attn.qkv.weight                  | cuda:0     | False           | Block 8\n",
      "- backbone.blocks.8.attn.qkv.bias                    | cuda:0     | False           | Block 8\n",
      "- backbone.blocks.8.attn.proj.weight                 | cuda:0     | False           | Block 8\n",
      "- backbone.blocks.8.attn.proj.bias                   | cuda:0     | False           | Block 8\n",
      "- backbone.blocks.8.norm2.weight                     | cuda:0     | False           | Block 8\n",
      "- backbone.blocks.8.norm2.bias                       | cuda:0     | False           | Block 8\n",
      "- backbone.blocks.8.mlp.fc1.weight                   | cuda:0     | False           | Block 8\n",
      "- backbone.blocks.8.mlp.fc1.bias                     | cuda:0     | False           | Block 8\n",
      "- backbone.blocks.8.mlp.fc2.weight                   | cuda:0     | False           | Block 8\n",
      "- backbone.blocks.8.mlp.fc2.bias                     | cuda:0     | False           | Block 8\n",
      "- backbone.blocks.9.norm1.weight                     | cuda:0     | True            | Block 9\n",
      "- backbone.blocks.9.norm1.bias                       | cuda:0     | True            | Block 9\n",
      "- backbone.blocks.9.attn.qkv.weight                  | cuda:0     | True            | Block 9\n",
      "- backbone.blocks.9.attn.qkv.bias                    | cuda:0     | True            | Block 9\n",
      "- backbone.blocks.9.attn.proj.weight                 | cuda:0     | True            | Block 9\n",
      "- backbone.blocks.9.attn.proj.bias                   | cuda:0     | True            | Block 9\n",
      "- backbone.blocks.9.norm2.weight                     | cuda:0     | True            | Block 9\n",
      "- backbone.blocks.9.norm2.bias                       | cuda:0     | True            | Block 9\n",
      "- backbone.blocks.9.mlp.fc1.weight                   | cuda:0     | True            | Block 9\n",
      "- backbone.blocks.9.mlp.fc1.bias                     | cuda:0     | True            | Block 9\n",
      "- backbone.blocks.9.mlp.fc2.weight                   | cuda:0     | True            | Block 9\n",
      "- backbone.blocks.9.mlp.fc2.bias                     | cuda:0     | True            | Block 9\n",
      "- backbone.blocks.10.norm1.weight                    | cuda:0     | True            | Block 10\n",
      "- backbone.blocks.10.norm1.bias                      | cuda:0     | True            | Block 10\n",
      "- backbone.blocks.10.attn.qkv.weight                 | cuda:0     | True            | Block 10\n",
      "- backbone.blocks.10.attn.qkv.bias                   | cuda:0     | True            | Block 10\n",
      "- backbone.blocks.10.attn.proj.weight                | cuda:0     | True            | Block 10\n",
      "- backbone.blocks.10.attn.proj.bias                  | cuda:0     | True            | Block 10\n",
      "- backbone.blocks.10.norm2.weight                    | cuda:0     | True            | Block 10\n",
      "- backbone.blocks.10.norm2.bias                      | cuda:0     | True            | Block 10\n",
      "- backbone.blocks.10.mlp.fc1.weight                  | cuda:0     | True            | Block 10\n",
      "- backbone.blocks.10.mlp.fc1.bias                    | cuda:0     | True            | Block 10\n",
      "- backbone.blocks.10.mlp.fc2.weight                  | cuda:0     | True            | Block 10\n",
      "- backbone.blocks.10.mlp.fc2.bias                    | cuda:0     | True            | Block 10\n",
      "- backbone.blocks.11.norm1.weight                    | cuda:0     | True            | Block 11\n",
      "- backbone.blocks.11.norm1.bias                      | cuda:0     | True            | Block 11\n",
      "- backbone.blocks.11.attn.qkv.weight                 | cuda:0     | True            | Block 11\n",
      "- backbone.blocks.11.attn.qkv.bias                   | cuda:0     | True            | Block 11\n",
      "- backbone.blocks.11.attn.proj.weight                | cuda:0     | True            | Block 11\n",
      "- backbone.blocks.11.attn.proj.bias                  | cuda:0     | True            | Block 11\n",
      "- backbone.blocks.11.norm2.weight                    | cuda:0     | True            | Block 11\n",
      "- backbone.blocks.11.norm2.bias                      | cuda:0     | True            | Block 11\n",
      "- backbone.blocks.11.mlp.fc1.weight                  | cuda:0     | True            | Block 11\n",
      "- backbone.blocks.11.mlp.fc1.bias                    | cuda:0     | True            | Block 11\n",
      "- backbone.blocks.11.mlp.fc2.weight                  | cuda:0     | True            | Block 11\n",
      "- backbone.blocks.11.mlp.fc2.bias                    | cuda:0     | True            | Block 11\n",
      "- backbone.norm.weight                               | cuda:0     | True            | N/A\n",
      "- backbone.norm.bias                                 | cuda:0     | True            | N/A\n",
      "- classifier.0.weight                                | cuda:0     | True            | N/A\n",
      "- classifier.0.bias                                  | cuda:0     | True            | N/A\n",
      "- classifier.3.weight                                | cuda:0     | True            | N/A\n",
      "- classifier.3.bias                                  | cuda:0     | True            | N/A\n",
      "Model is in training mode.\n",
      "--- End Debugging Model ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "debug_model(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "A-GWt2WqlJyY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1746828026805,
     "user": {
      "displayName": "Niccolò",
      "userId": "00690440481202077065"
     },
     "user_tz": -120
    },
    "id": "A-GWt2WqlJyY",
    "outputId": "ee0d6244-5233-445e-9ebb-e6656c322474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DinoClassifier(\n",
      "  (backbone): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "    (head): Identity()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=100, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "RqiWVe89NEJC",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1746828026807,
     "user": {
      "displayName": "Niccolò",
      "userId": "00690440481202077065"
     },
     "user_tz": -120
    },
    "id": "RqiWVe89NEJC"
   },
   "outputs": [],
   "source": [
    "# --- OPTIMIZER AND LOSS FUNCTION ---\n",
    "learning_rate = 1e-4\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-5\n",
    "epochs = 50\n",
    "\n",
    "\"\"\"\n",
    "# Example for differential learning rates:\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': model.backbone.blocks[9:].parameters(), 'lr': 1e-5}, # Adjust block indices if needed\n",
    "    # You might also want to fine-tune backbone.norm if it exists and is not frozen\n",
    "    # {'params': model.backbone.norm.parameters(), 'lr': 1e-5},\n",
    "    {'params': model.classifier.parameters(), 'lr': 1e-4}\n",
    "], weight_decay=0.05) # example weight decay\n",
    "\"\"\"\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "# Example optimizer instantiation:\n",
    "optimizer = torch.optim.SGD(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=learning_rate, # Example LR\n",
    "    weight_decay=weight_decay,\n",
    "    momentum=momentum\n",
    ")\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "w2WnTA_ue2sX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "executionInfo": {
     "elapsed": 1400,
     "status": "ok",
     "timestamp": 1746828028204,
     "user": {
      "displayName": "Niccolò",
      "userId": "00690440481202077065"
     },
     "user_tz": -120
    },
    "id": "w2WnTA_ue2sX",
    "outputId": "f237b3e2-33ed-400e-ac88-dc71ace4282c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/drive/MyDrive/FL/wandb/run-20250509_220022-yw9h33jo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nicco-to-politecnico-di-torino/FederatedProject/runs/yw9h33jo' target=\"_blank\">dino_vits16_run</a></strong> to <a href='https://wandb.ai/nicco-to-politecnico-di-torino/FederatedProject' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nicco-to-politecnico-di-torino/FederatedProject' target=\"_blank\">https://wandb.ai/nicco-to-politecnico-di-torino/FederatedProject</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nicco-to-politecnico-di-torino/FederatedProject/runs/yw9h33jo' target=\"_blank\">https://wandb.ai/nicco-to-politecnico-di-torino/FederatedProject/runs/yw9h33jo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb.init() prepares the tracking of hyperparameters/metrics for later recording performance using wandb.log()\n",
    "\n",
    "model_name = \"dino_vits16\"\n",
    "project_name = \"FederatedProject\"\n",
    "run_name = f\"{model_name}_run\"\n",
    "\n",
    "# INITIALIZE W&B\n",
    "wandb.init(\n",
    "    project=project_name,\n",
    "    name=run_name,\n",
    "    config={\n",
    "        \"model\": \"dino_vits16\",\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": train_loader.batch_size,\n",
    "        \"learning_rate\": learning_rate,  # Use fixed value\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"momentum\": momentum,\n",
    "        \"architecture\": model.__class__.__name__,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Copy your config\n",
    "config = wandb.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mo4lpz6c3C-F",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1746828028220,
     "user": {
      "displayName": "Niccolò",
      "userId": "00690440481202077065"
     },
     "user_tz": -120
    },
    "id": "mo4lpz6c3C-F"
   },
   "outputs": [],
   "source": [
    "#  PERCORSO CHECKPOINT\n",
    "checkpoint_dir = \"/content/drive/MyDrive/FL/FederatedLearningProject/checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cBdBMnxzyusN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1746828122790,
     "user": {
      "displayName": "Niccolò",
      "userId": "00690440481202077065"
     },
     "user_tz": -120
    },
    "id": "cBdBMnxzyusN",
    "outputId": "89c639a1-6b9a-46f4-c2c7-b5befb22e268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Nessun checkpoint trovato, inizio da epoca 1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RECOVER CHECKPOINT\n",
    "# # the function already do model.load_state_dict(checkpoint_data[\"model_state_dict\"])\n",
    "#                           scheduler.load_state_dict(checkpoint_data[\"scheduler_state_dict\"])\n",
    "#                           optimizer.load_state_dict(checkpoint_data[\"optimizer_state_dict\"])\n",
    "# anyway it returns all the data (model data) if needed\n",
    "\n",
    "start_epoch, model_data = checkpointing.load_checkpoint(model, optimizer, checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ZGaA_bF5Cpy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 927130,
     "status": "error",
     "timestamp": 1746829104981,
     "user": {
      "displayName": "Niccolò",
      "userId": "00690440481202077065"
     },
     "user_tz": -120
    },
    "id": "3ZGaA_bF5Cpy",
    "outputId": "e315b21c-e2c9-489a-9e6f-74b304a9673a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 4.6615, Train Accuracy: 1.84%, Val Loss: 4.4592, Val Accuracy: 3.93%\n",
      "[Epoch 2] Train Loss: 3.9377, Train Accuracy: 12.24%, Val Loss: 3.3714, Val Accuracy: 22.09%\n",
      "[Epoch 3] Train Loss: 3.0359, Train Accuracy: 27.64%, Val Loss: 2.8054, Val Accuracy: 31.85%\n",
      "[Epoch 4] Train Loss: 2.6574, Train Accuracy: 33.95%, Val Loss: 2.5774, Val Accuracy: 35.54%\n",
      "[Epoch 5] Train Loss: 2.4771, Train Accuracy: 37.35%, Val Loss: 2.4359, Val Accuracy: 38.24%\n",
      "[Epoch 6] Train Loss: 2.3522, Train Accuracy: 39.91%, Val Loss: 2.3486, Val Accuracy: 40.09%\n",
      "[Epoch 7] Train Loss: 2.2645, Train Accuracy: 41.39%, Val Loss: 2.2770, Val Accuracy: 41.36%\n",
      "[Epoch 8] Train Loss: 2.1905, Train Accuracy: 42.92%, Val Loss: 2.2269, Val Accuracy: 42.97%\n",
      "[Epoch 9] Train Loss: 2.1295, Train Accuracy: 44.65%, Val Loss: 2.1706, Val Accuracy: 43.40%\n",
      "[Epoch 10] Train Loss: 2.0821, Train Accuracy: 45.40%, Val Loss: 2.1414, Val Accuracy: 44.14%\n",
      "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/dino_vits16_checkpoint.pth\n",
      "[Epoch 11] Train Loss: 2.0419, Train Accuracy: 46.26%, Val Loss: 2.1093, Val Accuracy: 44.77%\n",
      "[Epoch 12] Train Loss: 2.0070, Train Accuracy: 47.11%, Val Loss: 2.0807, Val Accuracy: 45.46%\n",
      "[Epoch 13] Train Loss: 1.9739, Train Accuracy: 47.84%, Val Loss: 2.0594, Val Accuracy: 45.84%\n",
      "[Epoch 14] Train Loss: 1.9477, Train Accuracy: 48.31%, Val Loss: 2.0547, Val Accuracy: 46.02%\n",
      "[Epoch 15] Train Loss: 1.9174, Train Accuracy: 48.70%, Val Loss: 2.0288, Val Accuracy: 46.41%\n",
      "[Epoch 16] Train Loss: 1.8999, Train Accuracy: 49.17%, Val Loss: 2.0068, Val Accuracy: 46.94%\n",
      "[Epoch 17] Train Loss: 1.8570, Train Accuracy: 50.19%, Val Loss: 1.9993, Val Accuracy: 47.32%\n",
      "[Epoch 18] Train Loss: 1.8391, Train Accuracy: 50.48%, Val Loss: 1.9814, Val Accuracy: 47.84%\n",
      "[Epoch 19] Train Loss: 1.8223, Train Accuracy: 50.91%, Val Loss: 1.9637, Val Accuracy: 48.20%\n",
      "[Epoch 20] Train Loss: 1.7991, Train Accuracy: 51.58%, Val Loss: 1.9469, Val Accuracy: 48.68%\n",
      "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/dino_vits16_checkpoint.pth\n",
      "[Epoch 21] Train Loss: 1.7871, Train Accuracy: 51.66%, Val Loss: 1.9341, Val Accuracy: 48.65%\n",
      "[Epoch 22] Train Loss: 1.7609, Train Accuracy: 52.19%, Val Loss: 1.9395, Val Accuracy: 48.92%\n",
      "[Epoch 23] Train Loss: 1.7507, Train Accuracy: 52.56%, Val Loss: 1.9393, Val Accuracy: 48.72%\n",
      "[Epoch 24] Train Loss: 1.7325, Train Accuracy: 53.31%, Val Loss: 1.9218, Val Accuracy: 49.08%\n",
      "[Epoch 25] Train Loss: 1.7113, Train Accuracy: 53.61%, Val Loss: 1.9177, Val Accuracy: 49.36%\n",
      "[Epoch 26] Train Loss: 1.6955, Train Accuracy: 53.93%, Val Loss: 1.9151, Val Accuracy: 49.36%\n",
      "[Epoch 27] Train Loss: 1.6741, Train Accuracy: 54.43%, Val Loss: 1.9048, Val Accuracy: 49.46%\n",
      "[Epoch 28] Train Loss: 1.6658, Train Accuracy: 54.76%, Val Loss: 1.8894, Val Accuracy: 50.08%\n",
      "[Epoch 29] Train Loss: 1.6483, Train Accuracy: 54.87%, Val Loss: 1.8769, Val Accuracy: 50.30%\n",
      "[Epoch 30] Train Loss: 1.6372, Train Accuracy: 55.57%, Val Loss: 1.8780, Val Accuracy: 50.06%\n",
      "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/dino_vits16_checkpoint.pth\n",
      "[Epoch 31] Train Loss: 1.6199, Train Accuracy: 55.50%, Val Loss: 1.8977, Val Accuracy: 49.45%\n",
      "[Epoch 32] Train Loss: 1.6083, Train Accuracy: 55.89%, Val Loss: 1.8765, Val Accuracy: 50.32%\n",
      "[Epoch 33] Train Loss: 1.5890, Train Accuracy: 56.18%, Val Loss: 1.8678, Val Accuracy: 50.46%\n",
      "[Epoch 34] Train Loss: 1.5769, Train Accuracy: 56.62%, Val Loss: 1.8662, Val Accuracy: 50.31%\n",
      "[Epoch 35] Train Loss: 1.5639, Train Accuracy: 56.76%, Val Loss: 1.8552, Val Accuracy: 50.40%\n",
      "[Epoch 36] Train Loss: 1.5551, Train Accuracy: 57.26%, Val Loss: 1.8472, Val Accuracy: 50.90%\n",
      "[Epoch 37] Train Loss: 1.5420, Train Accuracy: 57.47%, Val Loss: 1.8430, Val Accuracy: 50.75%\n",
      "[Epoch 38] Train Loss: 1.5289, Train Accuracy: 57.77%, Val Loss: 1.8511, Val Accuracy: 50.86%\n",
      "[Epoch 39] Train Loss: 1.5157, Train Accuracy: 58.09%, Val Loss: 1.8429, Val Accuracy: 50.99%\n",
      "[Epoch 40] Train Loss: 1.4981, Train Accuracy: 58.53%, Val Loss: 1.8435, Val Accuracy: 50.90%\n",
      "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/dino_vits16_checkpoint.pth\n",
      "[Epoch 41] Train Loss: 1.4845, Train Accuracy: 59.05%, Val Loss: 1.8382, Val Accuracy: 51.22%\n",
      "[Epoch 42] Train Loss: 1.4688, Train Accuracy: 59.16%, Val Loss: 1.8273, Val Accuracy: 51.47%\n",
      "[Epoch 43] Train Loss: 1.4655, Train Accuracy: 59.52%, Val Loss: 1.8236, Val Accuracy: 51.35%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6f7b7442876a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# --- TRAINING LOOP ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Call to the training loop function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_and_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/drive/MyDrive/FL/FederatedLearningProject/training/centralized_training.py\u001b[0m in \u001b[0;36mtrain_and_validate\u001b[0;34m(start_epoch, model, train_loader, val_loader, scheduler, optimizer, criterion, device, checkpoint_path, num_epochs, checkpoint_interval)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/FL/FederatedLearningProject/training/centralized_training.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, scheduler, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtotal_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- TRAINING LOOP ---\n",
    "# Call to the training loop function\n",
    "train_and_validate(start_epoch, model=model, train_loader=train_loader, val_loader=val_loader, scheduler=scheduler, optimizer=optimizer, criterion=criterion, device=device, checkpoint_path=checkpoint_path, num_epochs=50, checkpoint_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lCT7l21Lpl9L",
   "metadata": {
    "executionInfo": {
     "elapsed": 915159,
     "status": "aborted",
     "timestamp": 1746829104994,
     "user": {
      "displayName": "Niccolò",
      "userId": "00690440481202077065"
     },
     "user_tz": -120
    },
    "id": "lCT7l21Lpl9L"
   },
   "outputs": [],
   "source": [
    "## Display some informations ##\n",
    "\n",
    "print(\"Model:\", model_name)\n",
    "print(\"Train set size:\", len(train_set))\n",
    "print(\"Validation set size:\", len(val_set))\n",
    "print(\"Batch size:\", train_loader.batch_size)\n",
    "print(\"Number of epochs:\", config.epochs)\n",
    "print(\"DataLoader: \")\n",
    "print(\"Learning rate:\", optimizer.param_groups[0]['lr'])\n",
    "print(\"Architecture:\", model.__class__.__name__)\n",
    "print(\"Device:\", device)\n",
    "print(\"Optimizer:\", optimizer)\n",
    "print(\"Loss function:\", criterion)\n",
    "print(\"Checkpoint directory:\", checkpoint_dir)\n",
    "print(\"Checkpoint path:\", checkpoint_path)\n",
    "print(\"Current epoch:\", epoch)\n",
    "print()\n",
    "\n",
    "print(\"Train Loader Information:\")\n",
    "print(f\"  Number of batches: {len(train_loader)}\")\n",
    "print(f\"  Batch size: {train_loader.batch_size}\")\n",
    "# Get the dimension of a single batch\n",
    "for images, labels in train_loader:\n",
    "  print(f\"  Dimension of 1 batch (images): {images.shape}\")\n",
    "  print(f\"  Dimension of 1 batch (labels): {labels.shape}\")\n",
    "  break  # Exit the loop after processing one batch\n",
    "print()\n",
    "\n",
    "print(\"\\nValidation Loader Information:\")\n",
    "print(f\"  Number of batches: {len(val_loader)}\")\n",
    "print(f\"  Batch size: {val_loader.batch_size}\")\n",
    "# Get the dimension of a single batch\n",
    "for images, labels in val_loader:\n",
    "  print(f\"  Dimension of 1 batch (images): {images.shape}\")\n",
    "  print(f\"  Dimension of 1 batch (labels): {labels.shape}\")\n",
    "  break  # Exit the loop after processing one batch\n",
    "print()\n",
    "\n",
    "# Check for CUDA availability\n",
    "print(\"CUDA AVAIABILITY:\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"Current GPU:\", torch.cuda.current_device())\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Print model architecture summary\n",
    "print(\"\\nMODEL ARCHITECTURE:\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jjZgRPO6D0s4",
   "metadata": {
    "id": "jjZgRPO6D0s4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
