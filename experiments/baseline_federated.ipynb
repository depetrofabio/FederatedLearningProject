{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI5ZodfKi0Tv",
        "outputId": "975103e9-1859-49b5-c3a1-adba09620172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import wandb\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import shutil\n",
        "import os                              # Import the 'os' module for changing directories\n",
        "os.chdir('/content/drive/MyDrive/FL')  # Change the directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o1GvZJCli0Ty"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torch.utils.data import Subset, DataLoader, random_split\n",
        "\n",
        "from FederatedLearningProject.data.cifar100_loader import get_cifar100\n",
        "import FederatedLearningProject.checkpoints.checkpointing as checkpointing\n",
        "from FederatedLearningProject.training.FL_training import train_server\n",
        "from FederatedLearningProject.experiments import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "nYj7zXB0i0Tz",
        "outputId": "090e02e3-5683-4a4a-e3b8-c6bc78bf1d2f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdepetrofabio\u001b[0m (\u001b[33mdepetrofabio-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "wandb.login() # Ask for your APIw key for logging in to the wandb library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzF7Eu1Di0Tz",
        "outputId": "f07369fa-4dc7-4079-eaef-bffae78fa576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in Training Set:   40000\n",
            "Number of images in Validation Set: 10000\n",
            "Number of images in Test Set:       10000\n",
            "‚úÖ Datasets loaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Import CIFAR100 dataset: train_set, val_set, test_set\n",
        "# The transforms are applied before returning the dataset (in the module)\n",
        "\n",
        "valid_split_perc = 0.2  # of the 50000 training data\n",
        "train_set, val_set, test_set = get_cifar100(valid_split_perc=valid_split_perc)\n",
        "# batch_size √® in hyperparameter (64, 128, ..), anche num_workers (consigliato per colab 2 o 4)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_set, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIEZCeBqdzoW",
        "outputId": "5ff87dad-72d3-4d2e-9026-c810cf91c800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/dino/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dino/dino_deitsmall16_pretrain/dino_deitsmall16_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dino_deitsmall16_pretrain.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 82.7M/82.7M [00:00<00:00, 293MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = models.LinearFlexibleDino(num_layers_to_freeze=12) # num_layers_to_freeze"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.debug()"
      ],
      "metadata": {
        "id": "AeTVfUPweV-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to_cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruFmUTTJPpfm",
        "outputId": "38550e1f-df08-413d-cbe8-ebf49e202b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "moving model to cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0irRZ7_ci0T1"
      },
      "source": [
        "## FedAvg Hyperparameters\n",
        "\n",
        "\n",
        "The Federated Averaging (FedAvg) algorithm involves several important hyperparameters that influence the performance and efficiency of training. Below is a detailed description of each:\n",
        "\n",
        "- **`num_clients (K)`**  \n",
        "  Total number of clients (or devices) participating in the federated learning system.  \n",
        "  Example: `num_clients = 100`\n",
        "\n",
        "- **`fraction (C)`**  \n",
        "  The fraction of clients selected to participate in each communication round. Must be a float between 0 and 1.  \n",
        "  Example: `fraction = 0.1` means 10% of clients are selected in each round.\n",
        "\n",
        "- **`local_epochs (E)`**  \n",
        "  Number of local training epochs each selected client performs before sending updates back to the server.  \n",
        "  Example: `local_epochs = 5`.\n",
        "  Recall that E is in the pseudocode while in the pdf that the professor assigned us is called **J** .\n",
        "\n",
        "  - **`num_rounds`**  \n",
        "  Total number of communication rounds (or global iterations) the server runs to aggregate updates and refine the global model.  \n",
        "  üìå *Example:* `num_rounds = 100`. This is up to us to define based on convergence and time/compute budget.\n",
        "\n",
        "- **Additional Notes:**  \n",
        "  These hyperparameters directly affect convergence speed, communication cost, and model performance.  \n",
        "  - A smaller `C` reduces communication overhead but may slow convergence.  \n",
        "  - A larger `E` can improve local model performance but may lead to model divergence if clients‚Äô data distributions are highly non-IID.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbO__W7Si0T2"
      },
      "source": [
        "The first FL baseline\n",
        "Implement the algorithm described in [10], fix K=100, C=0.1, adopt an iid sharding of the training set and fix J=4 the number of local steps. Run FedAvg on CIFAR-100 for a proper number of rounds (up to you to define, based on convergence and time/compute budget).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t1Kr_v1i0T2"
      },
      "source": [
        "# Federated Learning Baseline on CIFAR-100 using FedAvg\n",
        "\n",
        "In this experiment, we aim to implement and evaluate the Federated Averaging (FedAvg) algorithm as described in McMahan et al. [10], using a controlled setup on the CIFAR-100 dataset. This serves as a **baseline FL experiment** with standard hyperparameters for further comparative studies.\n",
        "\n",
        "## üìå Objectives\n",
        "\n",
        "- Implement the **FedAvg** algorithm.\n",
        "- Use **IID sharding** of CIFAR-100 to simulate a federated setting.\n",
        "- Fix key FL hyperparameters:\n",
        "  - Number of clients (**K**) = 100\n",
        "  - Fraction of participating clients per round (**C**) = 0.1\n",
        "  - Number of local update steps (**J**) = 4\n",
        "- Evaluate performance over a suitable number of communication rounds.\n",
        "\n",
        "## ‚öôÔ∏è Experiment Configuration\n",
        "\n",
        "| Parameter                  | Value        |\n",
        "|---------------------------|--------------|\n",
        "| Dataset                   | CIFAR-100    |\n",
        "| Model                     | DINO (TBD)   |\n",
        "| Total Clients (K)         | 100          |\n",
        "| Participation Fraction (C)| 0.1 (10 clients/round) |\n",
        "| Local Epochs (J)          | 4            |\n",
        "| Sharding Type             | IID          |\n",
        "| Rounds                    | *TBD based on convergence (e.g., 100‚Äì500)* |\n",
        "| Optimizer                 | SGD     |\n",
        "| Learning Rate             | *To be tuned*|\n",
        "\n",
        "## üìä Notes\n",
        "\n",
        "- **IID sharding** means the training data will be equally and randomly split among clients to avoid any data heterogeneity.\n",
        "- The number of rounds will be chosen based on **observed convergence behavior** and practical time/compute budget constraints.\n",
        "- Performance will be tracked using **validation/test accuracy** and **loss** over communication rounds.\n",
        "\n",
        "## üß† Why this setup?\n",
        "\n",
        "This configuration serves as a **standard benchmark** for future comparison with more advanced techniques (e.g., personalization, non-IID setups, compression, or asynchronous training). By fixing `K`, `C`, and `J`, and using IID data, we create a controlled environment to evaluate the basic performance of FedAvg.\n",
        "\n",
        "## üìö Reference\n",
        "\n",
        "[10] McMahan, Brendan, et al. *Communication-Efficient Learning of Deep Networks from Decentralized Data.* AISTATS 2017.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- OPTIMIZER AND LOSS FUNCTION ---\n",
        "\n",
        "\n",
        "learning_rate = 0.01  # best hyperparameter of the centralized\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0001 # best hyperparameter of the centralized\n",
        "\n",
        "num_clients = 100\n",
        "\n",
        "# Default hyperparameters for FedAvg\n",
        "num_local_steps = 4 #\n",
        "# num_local_steps = 8 #\n",
        "# num_local_steps = 16 #\n",
        "fraction = 0.1\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "\"\"\"\n",
        "# Example for differential learning rates:\n",
        "optimizer = torch.optim.AdamW([\n",
        "    {'params': model.backbone.blocks[9:].parameters(), 'lr': 1e-5}, # Adjust block indices if needed\n",
        "    # You might also want to fine-tune backbone.norm if it exists and is not frozen\n",
        "    # {'params': model.backbone.norm.parameters(), 'lr': 1e-5},\n",
        "    {'params': model.classifier.parameters(), 'lr': 1e-4}\n",
        "], weight_decay=0.05) # example weight decay\n",
        "\"\"\"\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
        "# Example optimizer instantiation:\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate, # Example LR\n",
        "    weight_decay=weight_decay,\n",
        "    momentum=momentum\n",
        ")\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "4adjcq8efEai"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# wandb.init() prepares the tracking of hyperparameters/metrics for later recording performance using wandb.log()\n",
        "\n",
        "\n",
        "\n",
        "# INITIALIZE W&B\n",
        "wandb.init(\n",
        "    project=project_name,\n",
        "    name=run_name,\n",
        "    config={\n",
        "        \"model\": model_name,\n",
        "        \"num_rounds\": num_rounds,\n",
        "        \"batch_size\": train_loader.batch_size,\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "        \"architecture\": model.__class__.__name__,\n",
        "})\n",
        "\n",
        "# Copy your config\n",
        "config = wandb.config\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "nEKnqO6UfHsI",
        "outputId": "f154cfa8-cbf5-4745-f824-8cdee2a7133e",
        "collapsed": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'num_rounds' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-13-2073119165.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     config={\n\u001b[1;32m     12\u001b[0m         \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;34m\"num_rounds\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;34m\"learning_rate\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_rounds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  PERCORSO CHECKPOINT\n",
        "\n",
        "checkpoint_dir = \"/content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/TestFinaliSingleModel\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "checkpoint_path = os.path.join(checkpoint_dir, f\"{model_name}_checkpoint.pth\")    # we predefine the name of the file inside the specified folder (dir)\n"
      ],
      "metadata": {
        "id": "6Y28_7dFfOpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RECOVER CHECKPOINT\n",
        "start_round, model_data = checkpointing.load_checkpoint_fedavg(model, optimizer, checkpoint_dir, model_name=model_name)\n",
        "\n",
        "\n",
        "try:\n",
        "  print()\n",
        "  print(f\"The 'model_data' dictionary contains the following keys: {list(model_data.keys())}\")\n",
        "  model.load_state_dict(model_data[\"model_state_dict\"])\n",
        "  optimizer.load_state_dict(model_data[\"optimizer_state_dict\"])\n",
        "except: None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sokst_ZcfOvP",
        "outputId": "44adbfe7-d60f-4c7a-9bd4-b5a6d21e9b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Nessun checkpoint trovato, inizio da round 1.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTstfTJ4i0T3",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from FederatedLearningProject.data.cifar100_loader import create_iid_splits\n",
        "client_dataset = create_iid_splits(train_set, num_clients = num_clients)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.LinearFlexibleDino(num_layers_to_freeze=12) # num_layers_to_freeze"
      ],
      "metadata": {
        "id": "NlwibLqVFCij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\""
      ],
      "metadata": {
        "id": "DdD-kuOiFhZd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_name = \"dino_vits16_J4\"\n",
        "project_name = \"FederatedProject\"\n",
        "run_name = f\"{model_name}_run\"\n"
      ],
      "metadata": {
        "id": "_ZESlQUmGTl-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_rounds_iterations = [200,300,400,500,600]\n",
        "# Loop through different num_rounds values\n",
        "for num_rounds_val in num_rounds_iterations:\n",
        "    # Re-initialize the model for each run to ensure fresh weights (or load a pre-trained one)\n",
        "    # If you want to start from the exact same initial state for each run,\n",
        "    # you might want to save the initial state_dict and load it here.\n",
        "    model = models.LinearFlexibleDino(num_layers_to_freeze=12) # Initialize your actual model here\n",
        "    model.to_cuda()\n",
        "\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=learning_rate,\n",
        "        weight_decay=weight_decay,\n",
        "        momentum=momentum\n",
        "    )\n",
        "\n",
        "    # Generate a unique run name for each iteration\n",
        "    run_name = f\"{model_name}_rounds_{num_rounds_val}\"\n",
        "\n",
        "    # INITIALIZE W&B for each new run\n",
        "    wandb.init(\n",
        "        project=project_name,\n",
        "        name=run_name,\n",
        "        config={\n",
        "            \"model\": model_name,\n",
        "            \"num_rounds\": num_rounds_val, # Use the current num_rounds_val\n",
        "            \"batch_size\": test_loader.batch_size, # Using test_loader's batch_size as a placeholder\n",
        "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "            \"weight_decay\": weight_decay,\n",
        "            \"momentum\": momentum,\n",
        "            \"architecture\": model.__class__.__name__,\n",
        "            \"num_local_steps\": num_local_steps,\n",
        "            \"fraction_clients\": fraction,\n",
        "        },\n",
        "        reinit=True # Important: Allows re-initialization of wandb in a loop\n",
        "    )\n",
        "\n",
        "    # Copy your config\n",
        "    config = wandb.config\n",
        "\n",
        "    # PERCORSO CHECKPOINT\n",
        "    checkpoint_dir = \"/content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/\"\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    # Make checkpoint path unique to the run if you want to store separate checkpoints\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f\"{model_name}_rounds_{num_rounds_val}_checkpoint.pth\")\n",
        "\n",
        "    # RECOVER CHECKPOINT (This part remains, but remember it will look for a checkpoint\n",
        "    # specific to the current `model_name` and `num_rounds_val` if you've made the path unique.)\n",
        "    start_round, model_data = checkpointing.load_checkpoint_fedavg(model, optimizer, checkpoint_dir, model_name=f\"{model_name}_rounds_{num_rounds_val}\")\n",
        "\n",
        "    try:\n",
        "      print()\n",
        "      print(f\"The 'model_data' dictionary contains the following keys: {list(model_data.keys())}\")\n",
        "      model.load_state_dict(model_data[\"model_state_dict\"])\n",
        "      optimizer.load_state_dict(model_data[\"optimizer_state_dict\"])\n",
        "    except:\n",
        "        print(\"Could not load model or optimizer state dictionary. Starting from scratch or with default initialization.\")\n",
        "\n",
        "    print(f\"\\n--- Starting training for num_rounds = {num_rounds_val} ---\")\n",
        "    train_server(model=model,\n",
        "                 num_clients=num_clients,\n",
        "                 num_client_steps=num_local_steps,\n",
        "                 num_rounds=num_rounds_val, # Pass the current num_rounds_val\n",
        "                 client_dataset=client_dataset,\n",
        "                 frac=fraction,\n",
        "                 optimizer=optimizer,\n",
        "                 device=device,\n",
        "                 batch_size=64,\n",
        "                 n_rounds_log=10,\n",
        "                 val_loader=val_loader,\n",
        "                 criterion=criterion,\n",
        "                 checkpoint_path=checkpoint_path,\n",
        "                 model_name=f\"{model_name}_rounds_{num_rounds_val}\") # Ensure model_name is unique for checkpointing\n",
        "\n",
        "    # End the current wandb run before starting the next one\n",
        "    wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CTTDWrKeFE7z",
        "outputId": "7b2f17f0-f0ef-4634-e1ac-3a494f74bb97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "moving model to cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to True."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>client_avg_accuracy</td><td>‚ñÅ</td></tr><tr><td>client_avg_loss</td><td>‚ñÅ</td></tr><tr><td>round</td><td>‚ñÅ</td></tr><tr><td>server_val_accuracy</td><td>‚ñÅ</td></tr><tr><td>server_val_loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>client_avg_accuracy</td><td>27.00583</td></tr><tr><td>client_avg_loss</td><td>3.1616</td></tr><tr><td>round</td><td>9</td></tr><tr><td>server_val_accuracy</td><td>29.12</td></tr><tr><td>server_val_loss</td><td>3.13042</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dino_vits16_J8_250round_rounds_200</strong> at: <a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject_single_dino/runs/4e1w6oga' target=\"_blank\">https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject_single_dino/runs/4e1w6oga</a><br> View project at: <a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject_single_dino' target=\"_blank\">https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject_single_dino</a><br>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250630_134559-4e1w6oga/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/FL/wandb/run-20250630_135043-hzyziqg1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject/runs/hzyziqg1' target=\"_blank\">dino_vits16_J4_rounds_200</a></strong> to <a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject' target=\"_blank\">https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject/runs/hzyziqg1' target=\"_blank\">https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject/runs/hzyziqg1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Nessun checkpoint trovato, inizio da round 1.\n",
            "\n",
            "Could not load model or optimizer state dictionary. Starting from scratch or with default initialization.\n",
            "\n",
            "--- Starting training for num_rounds = 200 ---\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 10/200\n",
            "Selected Clients: [92 33 75 21 41 36  0 46 88 43]\n",
            "Avg Client Loss: 4.2218 | Avg Client Accuracy: 13.20%\n",
            "Evaluation Loss:4.2730 | Val Accuracy: 13.23%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 20/200\n",
            "Selected Clients: [84 24 22 67 94 16 76 49 50 43]\n",
            "Avg Client Loss: 3.5273 | Avg Client Accuracy: 20.00%\n",
            "Evaluation Loss:3.4841 | Val Accuracy: 22.70%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 30/200\n",
            "Selected Clients: [42 89 51 69 99 39 40 55 93 36]\n",
            "Avg Client Loss: 3.0841 | Avg Client Accuracy: 25.82%\n",
            "Evaluation Loss:3.1271 | Val Accuracy: 27.93%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 40/200\n",
            "Selected Clients: [88  6 36 63 66 38 90  5 77 28]\n",
            "Avg Client Loss: 2.9266 | Avg Client Accuracy: 29.18%\n",
            "Evaluation Loss:2.9343 | Val Accuracy: 31.03%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 50/200\n",
            "Selected Clients: [55 72 42 75 48 37 38 63 96 70]\n",
            "Avg Client Loss: 2.7940 | Avg Client Accuracy: 31.72%\n",
            "Evaluation Loss:2.7792 | Val Accuracy: 33.33%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 60/200\n",
            "Selected Clients: [39 86 96 10 88 38 95 41 98 65]\n",
            "Avg Client Loss: 2.7358 | Avg Client Accuracy: 31.99%\n",
            "Evaluation Loss:2.6867 | Val Accuracy: 35.10%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 70/200\n",
            "Selected Clients: [29 61 55 93 48  3 79 54 69 53]\n",
            "Avg Client Loss: 2.6999 | Avg Client Accuracy: 33.52%\n",
            "Evaluation Loss:2.6049 | Val Accuracy: 36.31%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 80/200\n",
            "Selected Clients: [12 76 11 37 82 23 78 94 28 57]\n",
            "Avg Client Loss: 2.5756 | Avg Client Accuracy: 34.61%\n",
            "Evaluation Loss:2.5541 | Val Accuracy: 37.76%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 90/200\n",
            "Selected Clients: [48 74 51 34  9 43  4 38 39 30]\n",
            "Avg Client Loss: 2.5240 | Avg Client Accuracy: 37.27%\n",
            "Evaluation Loss:2.5162 | Val Accuracy: 38.30%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 100/200\n",
            "Selected Clients: [36 90 98 33 47 96 42 95 72 88]\n",
            "Avg Client Loss: 2.4974 | Avg Client Accuracy: 36.80%\n",
            "Evaluation Loss:2.4609 | Val Accuracy: 39.26%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 110/200\n",
            "Selected Clients: [84 63 40 92 74  1 22 20 29 42]\n",
            "Avg Client Loss: 2.4650 | Avg Client Accuracy: 38.40%\n",
            "Evaluation Loss:2.4169 | Val Accuracy: 39.96%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 120/200\n",
            "Selected Clients: [21 17 22 55 39 14 25 87 75 26]\n",
            "Avg Client Loss: 2.3835 | Avg Client Accuracy: 39.18%\n",
            "Evaluation Loss:2.3934 | Val Accuracy: 40.73%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 130/200\n",
            "Selected Clients: [59 43 48 74 20 65  3 29 85 37]\n",
            "Avg Client Loss: 2.3491 | Avg Client Accuracy: 39.65%\n",
            "Evaluation Loss:2.3666 | Val Accuracy: 41.13%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 140/200\n",
            "Selected Clients: [ 4 59 31 54 81 30 22 19 23 70]\n",
            "Avg Client Loss: 2.4036 | Avg Client Accuracy: 39.53%\n",
            "Evaluation Loss:2.3462 | Val Accuracy: 41.34%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 150/200\n",
            "Selected Clients: [ 4 42 66 89 17 12 79 21 77 28]\n",
            "Avg Client Loss: 2.4603 | Avg Client Accuracy: 37.62%\n",
            "Evaluation Loss:2.3325 | Val Accuracy: 41.89%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 160/200\n",
            "Selected Clients: [65 95 89 21 24 83 79 88 54 20]\n",
            "Avg Client Loss: 2.3596 | Avg Client Accuracy: 38.83%\n",
            "Evaluation Loss:2.3096 | Val Accuracy: 42.35%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 170/200\n",
            "Selected Clients: [88 40 18 58 85 13 61 65 83  0]\n",
            "Avg Client Loss: 2.3197 | Avg Client Accuracy: 41.09%\n",
            "Evaluation Loss:2.2899 | Val Accuracy: 42.65%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 180/200\n",
            "Selected Clients: [48 85 31 46 96 67 24 69 57 97]\n",
            "Avg Client Loss: 2.3894 | Avg Client Accuracy: 38.59%\n",
            "Evaluation Loss:2.2764 | Val Accuracy: 42.99%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 190/200\n",
            "Selected Clients: [88 54 81 95 87 60 48 37 52  4]\n",
            "Avg Client Loss: 2.2118 | Avg Client Accuracy: 42.03%\n",
            "Evaluation Loss:2.2736 | Val Accuracy: 43.18%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_200_checkpoint.pth\n",
            "\n",
            "Round 200/200\n",
            "Selected Clients: [79 89 87 28 64 77 29 74 34 73]\n",
            "Avg Client Loss: 2.3296 | Avg Client Accuracy: 41.60%\n",
            "Evaluation Loss:2.2614 | Val Accuracy: 43.68%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>client_avg_accuracy</td><td>‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà</td></tr><tr><td>client_avg_loss</td><td>‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>round</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>server_val_accuracy</td><td>‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>server_val_loss</td><td>‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>client_avg_accuracy</td><td>41.60156</td></tr><tr><td>client_avg_loss</td><td>2.32964</td></tr><tr><td>round</td><td>199</td></tr><tr><td>server_val_accuracy</td><td>43.68</td></tr><tr><td>server_val_loss</td><td>2.26143</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dino_vits16_J4_rounds_200</strong> at: <a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject/runs/hzyziqg1' target=\"_blank\">https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject/runs/hzyziqg1</a><br> View project at: <a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject' target=\"_blank\">https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250630_135043-hzyziqg1/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "moving model to cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/FL/wandb/run-20250630_135657-gk1y2xat</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject/runs/gk1y2xat' target=\"_blank\">dino_vits16_J4_rounds_300</a></strong> to <a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject' target=\"_blank\">https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject/runs/gk1y2xat' target=\"_blank\">https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject/runs/gk1y2xat</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Nessun checkpoint trovato, inizio da round 1.\n",
            "\n",
            "Could not load model or optimizer state dictionary. Starting from scratch or with default initialization.\n",
            "\n",
            "--- Starting training for num_rounds = 300 ---\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_300_checkpoint.pth\n",
            "\n",
            "Round 10/300\n",
            "Selected Clients: [95 43  9 11 26 76 53 14 89 47]\n",
            "Avg Client Loss: 4.2283 | Avg Client Accuracy: 12.42%\n",
            "Evaluation Loss:4.2434 | Val Accuracy: 13.98%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_300_checkpoint.pth\n",
            "\n",
            "Round 20/300\n",
            "Selected Clients: [36 82 93 41 81 30 55 31 21 11]\n",
            "Avg Client Loss: 3.4035 | Avg Client Accuracy: 21.29%\n",
            "Evaluation Loss:3.4683 | Val Accuracy: 23.40%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_300_checkpoint.pth\n",
            "\n",
            "Round 30/300\n",
            "Selected Clients: [90 96 54 36 23 87 81  0  8 97]\n",
            "Avg Client Loss: 3.1074 | Avg Client Accuracy: 25.78%\n",
            "Evaluation Loss:3.1280 | Val Accuracy: 28.12%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_300_checkpoint.pth\n",
            "\n",
            "Round 40/300\n",
            "Selected Clients: [ 2 74 65 49 28 70 18 62 71 85]\n",
            "Avg Client Loss: 2.9223 | Avg Client Accuracy: 29.80%\n",
            "Evaluation Loss:2.9190 | Val Accuracy: 31.49%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_300_checkpoint.pth\n",
            "\n",
            "Round 50/300\n",
            "Selected Clients: [31 53 85 17 84 96 27 86 34 97]\n",
            "Avg Client Loss: 2.9106 | Avg Client Accuracy: 29.77%\n",
            "Evaluation Loss:2.7946 | Val Accuracy: 33.02%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_300_checkpoint.pth\n",
            "\n",
            "Round 60/300\n",
            "Selected Clients: [42 47 21 66 30 81 50 16 59 45]\n",
            "Avg Client Loss: 2.6834 | Avg Client Accuracy: 33.05%\n",
            "Evaluation Loss:2.6836 | Val Accuracy: 34.85%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_300_checkpoint.pth\n",
            "\n",
            "Round 70/300\n",
            "Selected Clients: [14 68 97 62 61 26 91  7 45 19]\n",
            "Avg Client Loss: 2.6927 | Avg Client Accuracy: 33.16%\n",
            "Evaluation Loss:2.6221 | Val Accuracy: 36.24%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_300_checkpoint.pth\n",
            "\n",
            "Round 80/300\n",
            "Selected Clients: [56 93 58 59 34 37 41 25 70 86]\n",
            "Avg Client Loss: 2.5653 | Avg Client Accuracy: 35.12%\n",
            "Evaluation Loss:2.5514 | Val Accuracy: 37.84%\n",
            "--------------------------------------------------\n",
            "Checkpoint salvato su: /content/drive/MyDrive/FL/FederatedLearningProject/checkpoints/FL/dino_vits16_J4_rounds_300_checkpoint.pth\n",
            "\n",
            "Round 90/300\n",
            "Selected Clients: [77 53 81 76 25 50 12 61 19  1]\n",
            "Avg Client Loss: 2.5781 | Avg Client Accuracy: 36.33%\n",
            "Evaluation Loss:2.4864 | Val Accuracy: 38.62%\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_local_steps"
      ],
      "metadata": {
        "id": "2vm_5nXZGV1r",
        "outputId": "a7a1466b-0d7f-4631-8873-25e0af1e6bcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.debug()"
      ],
      "metadata": {
        "id": "GIzAcxiwiPKC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}