{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNxbHSv/l1i4VlsqGMzcGTn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MgypWE5qxJMY"},"outputs":[],"source":["import numpy as np\n","import wandb\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","import shutil\n","import os                              # Import the 'os' module for changing directories\n","os.chdir('/content/drive/MyDrive/FL')  # Change the directory\n","import datetime as datetime\n","import copy\n","import json"]},{"cell_type":"code","source":["import torch\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","import torch.nn as nn\n","\n","import torchvision\n","from torchvision import transforms\n","from torchvision.datasets import CIFAR100\n","from torch.utils.data import Subset, DataLoader, random_split\n","\n","from FederatedLearningProject.data.cifar100_loader import get_cifar100\n","from FederatedLearningProject.checkpoints.checkpointing import save_checkpoint, load_checkpoint\n","from FederatedLearningProject.training.centralized_training import train_and_validate, train_epoch, validate_epoch, log_to_wandb, generate_configs\n","from FederatedLearningProject.training.model_editing import compute_mask, SparseSGDM\n","\n","\n","import FederatedLearningProject.experiments.models as models\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"TGXs0e7sxQ2-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import CIFAR100 dataset: train_set, val_set, test_set\n","# The transforms are applied before returning the dataset (in the module)\n","valid_split_perc = 0.2    # of the 50000 training data\n","train_set, val_set, test_set = get_cifar100(valid_split_perc)"],"metadata":{"id":"6be95TRkxQ50"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create DataLoaders for training, validation, and test sets\n","# batch_size è in hyperparameter (64, 128, ..), anche num_workers (consigliato per colab 2 o 4)\n","train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=2)\n","test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)"],"metadata":{"id":"NewGgjnoxRHK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["o_model = models.LinearFlexibleDino()     # original model\n","o_model.freeze(12)\n","o_model.to_cuda()\n","o_model.debug()"],"metadata":{"id":"BsrZip59xa2K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prendo il path dello state_dict del miglio modello che ho salvato su Drive per non dover ri-trainare sempre\n","checkpoint_dir = \"/content/drive/MyDrive/FL/FederatedLearningProject/checkpoints\"\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","best_model_path = os.path.join(checkpoint_dir, \"best_model.pth\")"],"metadata":{"id":"YF1NUnhRxeno"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# copio il modello di base\n","model = copy.deepcopy(o_model)\n","# aggiorno i pesi del modello con quelli trainati\n","model.load_state_dict(torch.load(best_model_path))"],"metadata":{"id":"hmts2WuJxfS-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.freeze(0)"],"metadata":{"id":"ukXbK2CrxlwQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# numero totale di parametri del modello:\n","total_params = sum(p.numel() for p in model.parameters())\n","print(f\"Numero totale di parametri: {total_params}\")\n","\n","# numero totale di parametri del modello attualmente allenabili:\n","trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(f\"Parametri attualmente allenabili (trainable): {trainable_params}\")"],"metadata":{"id":"z1kAcxLhxlzI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizzarli\n","for name, param in model.named_parameters():\n","    if 'embed' in name or 'cls_token' in name or 'backbone.norm' in name or 'head' in name:\n","        print(f\"{name} - shape: {param.shape}\")"],"metadata":{"id":"0pmMrFhBxuDN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Freezzarli\n","print(\"param.requires_grad = False: \")\n","for name, param in model.named_parameters():\n","    if 'embed' in name or 'cls_token' in name or 'backbone.norm' in name or 'head' in name:\n","        param.requires_grad = False\n","        print(f\"FROZEN: {name}\")\n"],"metadata":{"id":"42GZ7RyMxuOc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# numero totale di parametri del modello:\n","total_params = sum(p.numel() for p in model.parameters())\n","print(f\"Numero totale di parametri: {total_params}\")\n","\n","# numero totale di parametri del modello attualmente allenabili:\n","trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(f\"Parametri attualmente allenabili (trainable): {trainable_params}\")"],"metadata":{"id":"iAFlrA-Gxz1B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()"],"metadata":{"id":"ZX6laGX_x0QV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mascherina=compute_mask(model, train_loader, sparsity_target=0.9, R=5, num_examples=200, device='cuda')"],"metadata":{"id":"yFs5Z8d6x6KW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["fede"],"metadata":{"id":"ztDwukE7yJ9E"}},{"cell_type":"code","source":["# conta i parameteri totali - masked - non masked\n","def count_masked_params(mask):\n","    total_params = 0\n","    masked_params = 0\n","\n","    for key, mask_tensor in mask.items():\n","        total_params += mask_tensor.numel()          # total number of elements in this parameter\n","        masked_params += (mask_tensor == 0).sum().item()  # count how many elements are zero (masked)\n","\n","    unmasked_params = total_params - masked_params\n","\n","    print(f\"Total parameters: {total_params}\")\n","    print(f\"Masked parameters (zeros): {masked_params}\")\n","    print(f\"Unmasked parameters (ones): {unmasked_params}\")\n","\n","    return total_params, masked_params, unmasked_params\n","count_masked_params(mascherina)"],"metadata":{"id":"JJA3d93IyMGD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","# prendo mascherina e applico un pò di rumore per ottenere 100 maschere simili\n","\n","def crea_local_masks(mascherina, num_clients=100, noise_level=0.1, seed=42):\n","    torch.manual_seed(seed)\n","    random.seed(seed)\n","\n","    local_masks = []\n","\n","    for _ in range(num_clients):\n","        client_mask = {}\n","        for name, mask in mascherina.items():\n","            # Forza il tipo booleano per sicurezza\n","            mask = mask.bool()\n","\n","            # Genera rumore booleano con probabilità `noise_level`\n","            noise = (torch.rand_like(mask, dtype=torch.float32) < noise_level)\n","\n","            # XOR: inverte solo dove c'è rumore\n","            noisy_mask = mask ^ noise.bool()\n","\n","            client_mask[name] = noisy_mask\n","        local_masks.append(client_mask)\n","\n","    return local_masks\n","\n","local_masks = crea_local_masks(mascherina, num_clients=100, noise_level=0.1, seed=42)"],"metadata":{"id":"XjtC7X9fyS0E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## output è la nostra global mask\n","\n","def aggregate_masks(local_masks, threshold_ratio=0.8):\n","    \"\"\"\n","    Aggrega n maschere locali in una maschera globale.\n","\n","    Args:\n","        local_masks (list of dict): Lista di maschere locali (bool tensor per parametro).\n","        threshold_ratio (float): Soglia minima (es. 0.5 significa 50% dei client).\n","\n","    Returns:\n","        dict: Maschera globale con stessi nomi dei parametri.\n","    \"\"\"\n","    if not local_masks:\n","        raise ValueError(\"La lista delle maschere locali è vuota!\")\n","\n","    num_clients = len(local_masks)\n","    threshold = int(num_clients * threshold_ratio)\n","\n","    # Inizializza l'accumulatore a zeri interi\n","    agg_mask = {\n","        name: torch.zeros_like(mask, dtype=torch.int32)\n","        for name, mask in local_masks[0].items()\n","    }\n","\n","    # Somma le maschere locali\n","    for cm in local_masks:\n","        for name in agg_mask:\n","            agg_mask[name] += cm[name].int()\n","\n","    # Crea la maschera finale con soglia\n","    final_mask = {\n","        name: (agg_mask[name] >= threshold)\n","        for name in agg_mask\n","    }\n","\n","    return final_mask\n"],"metadata":{"id":"2ImLLLk3yS28"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["global_mask = aggregate_masks(local_masks)\n","total_params, masked_params, unmasked_params = count_masked_params(global_mask)\n","print( (unmasked_params / total_params)*100 ) # % parametri masked nella global mask"],"metadata":{"id":"30tdWejxyiUb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","# Explanation of the `distribution_function`\n","\n","The `distribution_function` distributes the **unmasked** (i.e., active, True) parameters from a global mask `final_mask` exclusively among a given number of\n","clients.\n","\n","## Inputs:\n","- `final_mask`: a dictionary where keys correspond to model parameter names and values are boolean tensors indicating whether a parameter is active (True) or masked (False).\n","- `unmasked_params`: the total number of active (True) parameters in `final_mask`.\n","- `number_clients`: the number of clients to split the active parameters among.\n","\n","## Output:\n","- `client_masks`: a list of dictionaries (one per client), each with the same keys as `final_mask`. Each dictionary contains a mask where only a subset of parameters is active. These active positions are unique and do not overlap across clients.\n","\n","## How it works:\n","1. Computes how many active parameters to assign to each client (equally dividing the parameters with any remainder given to the last client).\n","2. Creates a list of all active positions in the global mask, recording for each position the parameter name and the flattened index.\n","3. Randomly shuffles this list to ensure random distribution.\n","4. Assigns a mutually exclusive subset of active parameters to each client, creating local masks with True only where assigned.\n","5. Ensures each client mask has all keys from the global mask, filling missing keys with all-False masks.\n","\n","## Result:\n","- Active parameters are partitioned exclusively and evenly (up to remainder) among clients.\n","- Summing all client masks recreates the original global mask.\n","- The last client receives any remained active parameters to handle uneven splits.\n","\n","---\n","\n","\n","\n"],"metadata":{"id":"Kjp-fYhTyrTG"}},{"cell_type":"code","source":["def distribution_function(final_mask, unmasked_params, number_clients):\n","    '''\n","    final_mask: dict of tensors with 1s and 0s (global mask)\n","    unmasked_params: total number of 1s in final_mask\n","    number_clients: number of clients to partition the unmasked parameters\n","\n","    Returns:\n","        client_masks: list of length = number_clients\n","                      each element is a dict (same keys as final_mask)\n","                      with 1s in unique positions (disjoint among clients)\n","    '''\n","    total_params = sum(m.numel() for m in final_mask.values())\n","    #print(f\"Totale parametri in final_mask: {total_params}\")\n","\n","    base_params_per_client = unmasked_params // number_clients\n","    remainder = unmasked_params % number_clients\n","\n","    client_masks = [dict() for _ in range(number_clients)]\n","\n","    # Costruiamo la lista di tutte le posizioni degli 1 nella maschera globale\n","    all_1_positions = []\n","    for key, mask_tensor in final_mask.items():\n","        ones_indices = torch.nonzero(mask_tensor.flatten(), as_tuple=False).squeeze()\n","        # ones_indices può essere un tensor 1D o 0D se solo 1 elemento\n","        if ones_indices.ndim == 0:\n","            ones_indices = ones_indices.unsqueeze(0)\n","        for idx in ones_indices.tolist():\n","            all_1_positions.append((key, idx))\n","\n","    # Shuffle\n","    torch.manual_seed(0)\n","    perm = torch.randperm(len(all_1_positions)).tolist()\n","    all_1_positions = [all_1_positions[i] for i in perm]\n","\n","    start_idx = 0\n","    for client_id in range(number_clients):\n","        count = base_params_per_client + (1 if client_id == number_clients - 1 else 0)\n","        subset = all_1_positions[start_idx:start_idx+count]\n","        start_idx += count\n","\n","        for key, flat_idx in subset:\n","            shape = final_mask[key].shape\n","            if key not in client_masks[client_id]:\n","                client_masks[client_id][key] = torch.zeros_like(final_mask[key], dtype=torch.bool)\n","            idx_unravel = torch.unravel_index(torch.tensor(flat_idx), shape)\n","            client_masks[client_id][key][idx_unravel] = True\n","\n","    # Per sicurezza, per ogni client assicuriamo che tutte le chiavi siano presenti:\n","    for client_mask in client_masks:\n","        for key in final_mask.keys():\n","            if key not in client_mask:\n","                client_mask[key] = torch.zeros_like(final_mask[key], dtype=torch.bool)\n","\n","    return client_masks\n"],"metadata":{"id":"I6PsGRDuytPj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["local_masks_parititioned = distribution_function(global_mask, unmasked_params, 100)"],"metadata":{"id":"PFhlxT4eywRO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_params, masked_params, unmasked_params = count_masked_params(local_masks_parititioned[50])\n","print( (unmasked_params / total_params)*100 ) # # % parametri masked in una local mask -> se funziona sara circa 0.1%"],"metadata":{"id":"R0PBgmjxywcU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["manca aggregazione task vector"],"metadata":{"id":"6TkX0dWOzGyR"}}]}