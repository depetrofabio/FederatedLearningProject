{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# IMPORT\n",
        "import numpy as np\n",
        "import wandb\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import shutil\n",
        "import os                              # Import the 'os' module for changing directories\n",
        "os.chdir('/content/drive/MyDrive/FL')  # Change the directory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0LweG_pBSd8",
        "outputId": "19e914e3-0733-43c0-be6e-08dd8a863497"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torch.utils.data import Subset, DataLoader, random_split\n",
        "\n",
        "from FederatedLearningProject.data.cifar100_loader import get_cifar100, create_iid_splits, create_non_iid_splits\n",
        "import FederatedLearningProject.checkpoints.checkpointing as checkpointing\n",
        "from FederatedLearningProject.training.FedMETA import aggregate_with_task_arithmetic, aggregate_masks_by_sparsity, aggregate_masks, distribution_function, train_server\n",
        "from FederatedLearningProject.training.model_editing import plot_all_layers_mask_sparsity\n",
        "\n",
        "from FederatedLearningProject.experiments import models\n",
        "import copy"
      ],
      "metadata": {
        "id": "rdG45zfHBdfd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "\n",
        "# Importa i moduli del tuo progetto\n",
        "from FederatedLearningProject.data import cifar100_loader\n",
        "from FederatedLearningProject import checkpoints\n",
        "from FederatedLearningProject.training import FedMETA, model_editing\n",
        "from FederatedLearningProject import experiments\n",
        "\n",
        "# Ricarica solo i moduli custom (NO torch)\n",
        "importlib.reload(cifar100_loader)\n",
        "importlib.reload(checkpoints.checkpointing)\n",
        "importlib.reload(FedMETA)\n",
        "importlib.reload(model_editing)\n",
        "importlib.reload(experiments.models)\n",
        "\n",
        "\n",
        "# Re-bind: importa di nuovo funzioni/classi/alias che usi nel codice\n",
        "from FederatedLearningProject.data.cifar100_loader import (\n",
        "    get_cifar100, create_iid_splits, create_non_iid_splits\n",
        ")\n",
        "\n",
        "import FederatedLearningProject.checkpoints.checkpointing as checkpointing\n",
        "\n",
        "from FederatedLearningProject.training.FedMETA import (\n",
        "    aggregate_with_task_arithmetic,\n",
        "    aggregate_masks,\n",
        "    distribution_function,\n",
        "    train_server\n",
        ")\n",
        "\n",
        "from FederatedLearningProject.training.model_editing import (\n",
        "    plot_all_layers_mask_sparsity\n",
        ")\n",
        "\n",
        "from FederatedLearningProject.experiments import models\n"
      ],
      "metadata": {
        "id": "CHeYsngVyf8z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login() # Ask for your APIw key for logging in to the wandb library."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "om6P1kf38H1F",
        "outputId": "477dd4c8-2c69-496f-96a9-6849b03065a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdepetrofabio\u001b[0m (\u001b[33mdepetrofabio-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "model_name = \"dino_vits16_J4\"\n",
        "project_name = \"FederatedProjectPROVA_PARTE4\"\n",
        "\n",
        "# Generate a unique run name for each iteration\n",
        "run_name = f\"{model_name}_rounds_prova\"\n",
        "# INITIALIZE W&B for each new run\n",
        "wandb.init(\n",
        "    project=project_name,\n",
        "    name=run_name,\n",
        "    config={\n",
        "        \"model\": model_name,\n",
        "        \"num_rounds\": 100, # Use the current num_rounds_val\n",
        "        \"batch_size\": 128, # Using test_loader's batch_size as a placeholder\n",
        "    },\n",
        "    reinit=True # Important: Allows re-initialization of wandb in a loop\n",
        ")\n",
        "\n",
        "# Copy your config\n",
        "config = wandb.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5q_imKpr8maZ",
        "outputId": "1aebf2fd-f871-448a-84c5-abf53b831788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to True."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dino_vits16_J4_rounds_prova</strong> at: <a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject/runs/6uingb69' target=\"_blank\">https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject/runs/6uingb69</a><br> View project at: <a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject' target=\"_blank\">https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProject</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250704_193940-6uingb69/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/FL/wandb/run-20250704_193950-0tmx920a</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProjectPROVA_PARTE4/runs/0tmx920a' target=\"_blank\">dino_vits16_J4_rounds_prova</a></strong> to <a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProjectPROVA_PARTE4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProjectPROVA_PARTE4' target=\"_blank\">https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProjectPROVA_PARTE4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProjectPROVA_PARTE4/runs/0tmx920a' target=\"_blank\">https://wandb.ai/depetrofabio-politecnico-di-torino/FederatedProjectPROVA_PARTE4/runs/0tmx920a</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the content of the folder FederatedLearningProject.data.masks\n",
        "print(os.listdir('FederatedLearningProject/masks'))\n",
        "\n",
        "val_set = torch.load('FederatedLearningProject/masks/val_set.pth', weights_only=False)\n",
        "train_set = torch.load('FederatedLearningProject/masks/train_set.pth', weights_only=False)\n",
        "test_set = torch.load('FederatedLearningProject/masks/test_set.pth', weights_only=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNXWWiquDGXR",
        "outputId": "3412a1c7-3f73-4dff-d28e-4161a788e244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train_set.pth', 'val_set.pth', 'test_set.pth', 'client_masks_iid.pth', 'client_masks_non_iid_1.pth']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o_model = models.LinearFlexibleDino(num_layers_to_freeze=12)\n",
        "local_masks = torch.load('FederatedLearningProject/masks/client_masks_non_iid_1.pth')\n",
        "#local_mask_iid = torch.load('FederatedLearningProject/masks/client_masks_iid.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF_H3hYjMbZJ",
        "outputId": "6abc8efd-161a-464b-ec7d-bcc68ef2a6b9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/dino/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dino/dino_deitsmall16_pretrain/dino_deitsmall16_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dino_deitsmall16_pretrain.pth\n",
            "100%|██████████| 82.7M/82.7M [00:00<00:00, 105MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o_model = models.LinearFlexibleDino(num_layers_to_freeze=12)\n",
        "local_masks = torch.load('FederatedLearningProject/masks/light_weight_masks_non_iid_1.pth')"
      ],
      "metadata": {
        "id": "F44_hMXApiCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = copy.deepcopy(o_model)\n",
        "model_checkpoint = torch.load(\"FederatedLearningProject/checkpoints/FL_NON_IID(1)/dino_vits_16_non_iid(1)_local_steps_4_checkpoint.pth\")"
      ],
      "metadata": {
        "id": "Iy6nS2UapjfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(model_checkpoint['model_state_dict'])\n",
        "#model.debug()"
      ],
      "metadata": {
        "id": "RQv1LOFQpl3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.unfreeze(12)\n",
        "#model.debug()"
      ],
      "metadata": {
        "id": "LHkIwwqKpolm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_mask = aggregate_masks_by_sparsity(local_masks, sparsity_target = 0.9)\n",
        "del local_masks"
      ],
      "metadata": {
        "id": "81P7dAN0po1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "partition_masks = distribution_function(final_mask, number_clients=100)"
      ],
      "metadata": {
        "id": "YYaXZurNpqC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client_dataset = create_non_iid_splits(train_set, num_clients=100, classes_per_client=1)    # each client will see only 1 class"
      ],
      "metadata": {
        "id": "cDwIbZ99prnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_config = {\n",
        "    'lr': 0.01,\n",
        "    'momentum': 0.9,\n",
        "    'weight_decay': 0.0001\n",
        "}\n",
        "\n",
        "model.to_cuda()\n",
        "\n",
        "checkpoint_path = 'FederatedLearningProject/checkpoints/'\n",
        "val_loader = DataLoader(val_set, batch_size=128, shuffle=True)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_server(model, num_rounds=100, client_dataset=client_dataset, client_masks=partition_masks, optimizer_config=optimizer_config, device='cuda', frac=0.1, batch_size=128, val_loader=val_loader, checkpoint_path=checkpoint_path, criterion=criterion)"
      ],
      "metadata": {
        "id": "7g4nulSkptEu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}